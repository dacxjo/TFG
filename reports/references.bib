@IEEEtranBSTCTL{IEEEexample:BSTcontrol,
  CTLuse_forced_etal = "yes",
  CTLmax_names_forced_etal = "6",
  CTLnames_show_etal = "1"
}

@misc{vaswani_attention_2023,
    title = {Attention {Is} {All} {You} {Need}},
    url = {http://arxiv.org/abs/1706.03762},
    doi = {10.48550/arXiv.1706.03762},
    abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
    language = {en},
    urldate = {2025-03-07},
    publisher = {arXiv},
    author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
    month = aug,
    year = {2023},
    note = {arXiv:1706.03762 [cs]},
    keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}
@article{kim_global_2025,
    title = {Global patterns and trends in breast cancer incidence and mortality across 185 countries},
    issn = {1078-8956, 1546-170X},
    url = {https://www.nature.com/articles/s41591-025-03502-3},
    doi = {10.1038/s41591-025-03502-3},
    language = {en},
    urldate = {2025-03-08},
    journal = {Nature Medicine},
    author = {Kim, Joanne and Harper, Andrew and McCormack, Valerie and Sung, Hyuna and Houssami, Nehmat and Morgan, Eileen and Mutebi, Miriam and Garvey, Gail and Soerjomataram, Isabelle and Fidler-Benaoudia, Miranda M.},
    month = feb,
    year = {2025},
}

@article{harnessing_2024,
author = {Wang, Yun and Bu, Na and Luan, Xiao-fei and Song, Qian-qian and Ma, Ba-Fang and Hao, Wenhui and Yan, Jing-jing and Wang, Li and Zheng, Xiao-ling and Maimaitiyiming, Yasen},
year = {2024},
month = {03},
pages = {},
title = {Harnessing the potential of long non-coding RNAs in breast cancer: from etiology to treatment resistance and clinical applications},
volume = {14},
journal = {Frontiers in Oncology},
doi = {10.3389/fonc.2024.1337579}
}

@misc{iarc2025press,
  author       = {International Agency for Research on Cancer},
  title        = {Breast cancer cases and deaths are projected to rise globally},
  howpublished = {Press Release No. 361, 24 February 2025},
  year         = {2025},
  institution  = {IARC},
  address      = {Lyon, France},
  url          = {https://www.iarc.who.int/wp-content/uploads/2025/02/pr361_E.pdf}
}
@article{wang_early_2017,
    title = {Early {Diagnosis} of {Breast} {Cancer}},
    volume = {17},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    issn = {1424-8220},
    url = {https://www.mdpi.com/1424-8220/17/7/1572},
    doi = {10.3390/s17071572},
    abstract = {Early-stage cancer detection could reduce breast cancer death rates significantly in the long-term. The most critical point for best prognosis is to identify early-stage cancer cells. Investigators have studied many breast diagnostic approaches, including mammography, magnetic resonance imaging, ultrasound, computerized tomography, positron emission tomography and biopsy. However, these techniques have some limitations such as being expensive, time consuming and not suitable for young women. Developing a high-sensitive and rapid early-stage breast cancer diagnostic method is urgent. In recent years, investigators have paid their attention in the development of biosensors to detect breast cancer using different biomarkers. Apart from biosensors and biomarkers, microwave imaging techniques have also been intensely studied as a promising diagnostic tool for rapid and cost-effective early-stage breast cancer detection. This paper aims to provide an overview on recent important achievements in breast screening methods (particularly on microwave imaging) and breast biomarkers along with biosensors for rapidly diagnosing breast cancer.},
    language = {en},
    number = {7},
    urldate = {2025-05-15},
    journal = {Sensors},
    author = {Wang, Lulu},
    month = jul,
    year = {2017},
    note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
    keywords = {biomarker, breast cancer, microwave biosensor, microwave imaging, microwave-sensing, radio frequency biosensor},
    pages = {1572},
}

@article{pattanaik_breast_2022,
    title = {Breast {Cancer} {Classification} from {Mammogram} {Images} {Using} {Extreme} {Learning} {Machine}-{Based} {DenseNet121} {Model}},
    volume = {2022},
    copyright = {Copyright © 2022 Raj Kumar Pattanaik et al.},
    issn = {1687-7268},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/2731364},
    doi = {10.1155/2022/2731364},
    abstract = {Breast cancer is characterized by abnormal discontinuities in the lining cells of a woman’s milk duct. Large numbers of women die from breast cancer as a result of developing symptoms in the milk ducts. If the diagnosis is made early, the death rates can be decreased. For radiologists and physicians, manually analyzing mammography images for breast cancer become time-consuming. To prevent manual analysis and simplify the work of classification, this paper introduces a novel hybrid DenseNet121-based Extreme Learning Machine Model (ELM) for classifying breast cancer from mammogram images. The mammogram images were processed through preprocessing and data augmentation phase. The features were collected separately after the pooling and flatten layer at the first stage of the classification. Further, the features are fed as input to the proposed DenseNet121-ELM model’s fully connected layer as input. An extreme learning machine model has replaced the fully connected layer. The weights of the extreme learning machine have been updated by the AdaGrad optimization algorithm to increase the model’s robustness and performance. Due to its faster convergence speed than other optimization techniques, the AdaGrad algorithm optimization was chosen. In this research, the Digital Database for Screening Mammography (DDSM) dataset mammogram images were utilized, and the results are presented. We have considered the batch size of 32, 64, and 128 for the performance measure, accuracy, sensitivity, specificity, and computational time. The proposed DenseNet121+ELM model achieves 99.47\% and 99.14\% as training accuracy and testing accuracy for batch size 128. Also, it achieves specificity, sensitivity, and computational time of 99.37\%, 99.94\%, and 159.7731 minutes, respectively. Further, the comparison result of performance measures is presented for batch sizes 32, 64, and 128 to show the robustness of the proposed DenseNet121+ELM model. The automatic classification performance of the DenseNet121+ELM model has much potential to be applied to the clinical diagnosis of breast cancer.},
    language = {en},
    number = {1},
    urldate = {2025-05-15},
    journal = {Journal of Sensors},
    author = {Pattanaik, Raj Kumar and Mishra, Satyasis and Siddique, Mohammed and Gopikrishna, Tiruveedula and Satapathy, Sunita},
    year = {2022},
    note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1155/2022/2731364},
    pages = {2731364},
}
@article{meenalochini_deep_2024,
    title = {A {Deep} {Learning} {Based} {Breast} {Cancer} {Classification} {System} {Using} {Mammograms}},
    volume = {19},
    issn = {2093-7423},
    url = {https://doi.org/10.1007/s42835-023-01747-x},
    doi = {10.1007/s42835-023-01747-x},
    abstract = {An automatic breast cancer detection and classification system plays an essential role in medical imaging applications. But accurate disease identification is one of the complicated processes due to the existence of noisy contents and irrelevant structure of the original images. In conventional works, various medical image processing techniques have been developed for accurately classifying the types of breast cancer. Still, it confronts difficulties due to the aspects of increased complexity in computations, error values, false positives, and misclassification outputs. Hence, this research work proposes to develop an optimization-based classification system for the breast cancer identification system. Here, the Gaussian filtering and Adaptive Histogram Equalization (AHE) techniques are utilized for preprocessing the original mammogram images by eliminating the noisy contents and enhancing the contrast of an image. Then, the Markov Random Adaptive Segmentation (MRAS) technique is employed for detecting the boundary region based on the random value selection. To make the classifying procedure easier, the set of features is optimally extracted from the segmented region with the help of a Genetic Algorithm (GA). In which, the global best fitness value is estimated by using the crossover, mutation, and selection operations. Finally, the Convolutional Neural Network (CNN) classification technique is utilized for categorizing the image as to whether normal or abnormal with its type. The entire performance analysis of the suggested model is validated and compared using multiple measures during the evaluation. In the proposed method GA performs feature selection and prunes unnecessary features. The major goal is to improve the classification performance while reducing the number of features used. The proposed system GA-CNN provides improved performance results with a reduced error rate.The suggested GA-CNN increases accuracy (98.5), sensitivity (99.38), and specificity values (98.4) as compared to the existing technique by effectively identifying the classed label.},
    language = {en},
    number = {4},
    urldate = {2025-05-15},
    journal = {Journal of Electrical Engineering \& Technology},
    author = {Meenalochini, G. and Ramkumar, S.},
    month = may,
    year = {2024},
    keywords = {Automated Pattern Recognition, Breast cancer detection, Categorization, Computer Imaging, Vision, Pattern Recognition and Graphics, Contrast enhancement, Convolutional neural network (CNN) based classification, Genetic algorithm, Genetic algorithm (GA) based optimization, Image Processing, Learning algorithms, Machine Learning, Markov random adaptive segmentation (MRAS), Preprocessing},
    pages = {2637--2650},
}
@article{zahoor_breast_2022,
    title = {Breast {Cancer} {Mammograms} {Classification} {Using} {Deep} {Neural} {Network} and {Entropy}-{Controlled} {Whale} {Optimization} {Algorithm}},
    volume = {12},
    issn = {2075-4418},
    url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8871265/},
    doi = {10.3390/diagnostics12020557},
    abstract = {Breast cancer has affected many women worldwide. To perform detection and classification of breast cancer many computer-aided diagnosis (CAD) systems have been established because the inspection of the mammogram images by the radiologist is a difficult and time taken task. To early diagnose the disease and provide better treatment lot of CAD systems were established. There is still a need to improve existing CAD systems by incorporating new methods and technologies in order to provide more precise results. This paper aims to investigate ways to prevent the disease as well as to provide new methods of classification in order to reduce the risk of breast cancer in women’s lives. The best feature optimization is performed to classify the results accurately. The CAD system’s accuracy improved by reducing the false-positive rates.The Modified Entropy Whale Optimization Algorithm (MEWOA) is proposed based on fusion for deep feature extraction and perform the classification. In the proposed method, the fine-tuned MobilenetV2 and Nasnet Mobile are applied for simulation. The features are extracted, and optimization is performed. The optimized features are fused and optimized by using MEWOA. Finally, by using the optimized deep features, the machine learning classifiers are applied to classify the breast cancer images. To extract the features and perform the classification, three publicly available datasets are used: INbreast, MIAS, and CBIS-DDSM. The maximum accuracy achieved in INbreast dataset is 99.7\%, MIAS dataset has 99.8\% and CBIS-DDSM has 93.8\%. Finally, a comparison with other existing methods is performed, demonstrating that the proposed algorithm outperforms the other approaches.},
    number = {2},
    urldate = {2025-05-15},
    journal = {Diagnostics},
    author = {Zahoor, Saliha and Shoaib, Umar and Lali, Ikram Ullah},
    month = feb,
    year = {2022},
    pmid = {35204646},
    pmcid = {PMC8871265},
    pages = {557},
}
@article{mota_breast_2024,
    title = {Breast {Cancer} {Molecular} {Subtype} {Prediction}: {A} {Mammography}-{Based} {AI} {Approach}},
    volume = {12},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    issn = {2227-9059},
    shorttitle = {Breast {Cancer} {Molecular} {Subtype} {Prediction}},
    url = {https://www.mdpi.com/2227-9059/12/6/1371},
    doi = {10.3390/biomedicines12061371},
    abstract = {Breast cancer remains a leading cause of mortality among women, with molecular subtypes significantly influencing prognosis and treatment strategies. Currently, identifying the molecular subtype of cancer requires a biopsy—a specialized, expensive, and time-consuming procedure, often yielding to results that must be supported with additional biopsies due to technique errors or tumor heterogeneity. This study introduces a novel approach for predicting breast cancer molecular subtypes using mammography images and advanced artificial intelligence (AI) methodologies. Using the OPTIMAM imaging database, 1397 images from 660 patients were selected. The pretrained deep learning model ResNet-101 was employed to classify tumors into five subtypes: Luminal A, Luminal B1, Luminal B2, HER2, and Triple Negative. Various classification strategies were studied: binary classifications (one vs. all others, specific combinations) and multi-class classification (evaluating all subtypes simultaneously). To address imbalanced data, strategies like oversampling, undersampling, and data augmentation were explored. Performance was evaluated using accuracy and area under the receiver operating characteristic curve (AUC). Binary classification results showed a maximum average accuracy and AUC of 79.02\% and 64.69\%, respectively, while multi-class classification achieved an average AUC of 60.62\% with oversampling and data augmentation. The most notable binary classification was HER2 vs. non-HER2, with an accuracy of 89.79\% and an AUC of 73.31\%. Binary classification for specific combinations of subtypes revealed an accuracy of 76.42\% for HER2 vs. Luminal A and an AUC of 73.04\% for HER2 vs. Luminal B1. These findings highlight the potential of mammography-based AI for non-invasive breast cancer subtype prediction, offering a promising alternative to biopsies and paving the way for personalized treatment plans.},
    language = {en},
    number = {6},
    urldate = {2025-05-15},
    journal = {Biomedicines},
    author = {Mota, Ana M. and Mendes, João and Matela, Nuno},
    month = jun,
    year = {2024},
    note = {Number: 6
Publisher: Multidisciplinary Digital Publishing Institute},
    keywords = {artificial intelligence, breast cancer, deep learning, mammography, molecular subtypes, personalized medicine},
    pages = {1371},
}
@article{ben_rabah_multimodal_2025,
    title = {A {Multimodal} {Deep} {Learning} {Model} for the {Classification} of {Breast} {Cancer} {Subtypes}},
    volume = {15},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    issn = {2075-4418},
    url = {https://www.mdpi.com/2075-4418/15/8/995},
    doi = {10.3390/diagnostics15080995},
    abstract = {Background: Breast cancer is a heterogeneous disease with distinct molecular subtypes, each requiring tailored therapeutic strategies. Accurate classification of these subtypes is crucial for optimizing treatment and improving patient outcomes. While immunohistochemistry remains the gold standard for subtyping, it is invasive and may not fully capture tumor heterogeneity. Artificial Intelligence (AI), particularly Deep Learning (DL), offers a promising non-invasive alternative by analyzing medical imaging data. Methods: In this study, we propose a multimodal DL model that integrates mammography images with clinical metadata to classify breast lesions into five categories: benign, luminal A, luminal B, HER2-enriched, and triple-negative. Using the publicly available Chinese Mammography Database (CMMD), our model was trained and evaluated on a dataset of 4056 images from 1775 patients. Results: The proposed multimodal approach significantly outperformed a unimodal model based solely on mammography images, achieving an AUC of 88.87\% for multiclass classification of these five categories, compared to 61.3\% AUC for the unimodal model. Conclusions: These findings highlight the potential of multimodal AI-driven approaches for non-invasive breast cancer subtype classification, paving the way for improved diagnostic precision and personalized treatment strategies.},
    language = {en},
    number = {8},
    urldate = {2025-04-18},
    journal = {Diagnostics},
    author = {Ben Rabah, Chaima and Sattar, Aamenah and Ibrahim, Ahmed and Serag, Ahmed},
    month = jan,
    year = {2025},
    note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
    keywords = {artificial intelligence, breast cancer, deep learning, molecular subtype classification, multimodal, personalized medicine},
    pages = {995},
}
@article{cai_online_2023,
    title = {An {Online} {Mammography} {Database} with {Biopsy} {Confirmed} {Types}},
    volume = {10},
    copyright = {2023 The Author(s)},
    issn = {2052-4463},
    url = {https://www.nature.com/articles/s41597-023-02025-1},
    doi = {10.1038/s41597-023-02025-1},
    abstract = {Breast carcinoma is the second largest cancer in the world among women. Early detection of breast cancer has been shown to increase the survival rate, thereby significantly increasing patients’ lifespan. Mammography, a noninvasive imaging tool with low cost, is widely used to diagnose breast disease at an early stage due to its high sensitivity. Although some public mammography datasets are useful, there is still a lack of open access datasets that expand beyond the white population as well as missing biopsy confirmation or with unknown molecular subtypes. To fill this gap, we build a database containing two online breast mammographies. The dataset named by Chinese Mammography Database (CMMD) contains 3712 mammographies involved 1775 patients, which is divided into two branches. The first dataset CMMD1 contains 1026 cases (2214 mammographies) with biopsy confirmed type of benign or malignant tumors. The second dataset CMMD2 includes 1498 mammographies for 749 patients with known molecular subtypes. Our database is constructed to enrich the diversity of mammography data and promote the development of relevant fields.},
    language = {en},
    number = {1},
    urldate = {2025-05-18},
    journal = {Scientific Data},
    author = {Cai, Hongmin and Wang, Jinhua and Dan, Tingting and Li, Jiao and Fan, Zhihao and Yi, Weiting and Cui, Chunyan and Jiang, Xinhua and Li, Li},
    month = mar,
    year = {2023},
    note = {Publisher: Nature Publishing Group},
    keywords = {Breast cancer, Prognostic markers},
    pages = {123},
}
@incollection{hussain_performance_2025,
    title = {Performance {Evaluation} of {Deep} {Learning} and {Transformer} {Models} {Using} {Multimodal} {Data} for {Breast} {Cancer} {Classification}},
    volume = {15199},
    url = {http://arxiv.org/abs/2410.10146},
    abstract = {Rising breast cancer (BC) occurrence and mortality are major global concerns for women. Deep learning (DL) has demonstrated superior diagnostic performance in BC classification compared to human expert readers. However, the predominant use of unimodal (digital mammography) features may limit the current performance of diagnostic models. To address this, we collected a novel multimodal dataset comprising both imaging and textual data. This study proposes a multimodal DL architecture for BC classification, utilising images (mammograms; four views) and textual data (radiological reports) from our new in-house dataset. Various augmentation techniques were applied to enhance the training data size for both imaging and textual data. We explored the performance of eleven SOTA DL architectures (VGG16, VGG19, ResNet34, ResNet50, MobileNet-v3, EffNet-b0, EffNet-b1, EffNet-b2, EffNet-b3, EffNet-b7, and Vision Transformer (ViT)) as imaging feature extractors. For textual feature extraction, we utilised either artificial neural networks (ANNs) or long short-term memory (LSTM) networks. The combined imaging and textual features were then inputted into an ANN classifier for BC classification, using the late fusion technique. We evaluated different feature extractor and classifier arrangements. The VGG19 and ANN combinations achieved the highest accuracy of 0.951. For precision, the VGG19 and ANN combination again surpassed other CNN and LSTM, ANN based architectures by achieving a score of 0.95. The best sensitivity score of 0.903 was achieved by the VGG16+LSTM. The highest F1 score of 0.931 was achieved by VGG19+LSTM. Only the VGG16+LSTM achieved the best area under the curve (AUC) of 0.937, with VGG16+LSTM closely following with a 0.929 AUC score.},
    urldate = {2025-05-19},
    author = {Hussain, Sadam and Ali, Mansoor and Naseem, Usman and Palomo, Beatriz Alejandra Bosques and Molina, Mario Alexis Monsivais and Abdala, Jorge Alberto Garza and Avalos, Daly Betzabeth Avendano and Cardona-Huerta, Servando and Gulliver, T. Aaron and Pena, Jose Gerardo Tamez},
    year = {2025},
    doi = {10.1007/978-3-031-73376-5_6},
    note = {arXiv:2410.10146 [eess]},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
    pages = {59--69},
}
@article{mckinney_international_2020,
    title = {International evaluation of an {AI} system for breast cancer screening},
    volume = {577},
    copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
    issn = {1476-4687},
    url = {https://www.nature.com/articles/s41586-019-1799-6},
    doi = {10.1038/s41586-019-1799-6},
    abstract = {Screening mammography aims to identify breast cancer at earlier stages of the disease, when treatment can be more successful1. Despite the existence of screening programmes worldwide, the interpretation of mammograms is affected by high rates of false positives and false negatives2. Here we present an artificial intelligence (AI) system that is capable of surpassing human experts in breast cancer prediction. To assess its performance in the clinical setting, we curated a large representative dataset from the UK and a large enriched dataset from the USA. We show an absolute reduction of 5.7\% and 1.2\% (USA and UK) in false positives and 9.4\% and 2.7\% in false negatives. We provide evidence of the ability of the system to generalize from the UK to the USA. In an independent study of six radiologists, the AI system outperformed all of the human readers: the area under the receiver operating characteristic curve (AUC-ROC) for the AI system was greater than the AUC-ROC for the average radiologist by an absolute margin of 11.5\%. We ran a simulation in which the AI system participated in the double-reading process that is used in the UK, and found that the AI system maintained non-inferior performance and reduced the workload of the second reader by 88\%. This robust assessment of the AI system paves the way for clinical trials to improve the accuracy and efficiency of breast cancer screening.},
    language = {en},
    number = {7788},
    urldate = {2025-05-19},
    journal = {Nature},
    author = {McKinney, Scott Mayer and Sieniek, Marcin and Godbole, Varun and Godwin, Jonathan and Antropova, Natasha and Ashrafian, Hutan and Back, Trevor and Chesus, Mary and Corrado, Greg S. and Darzi, Ara and Etemadi, Mozziyar and Garcia-Vicente, Florencia and Gilbert, Fiona J. and Halling-Brown, Mark and Hassabis, Demis and Jansen, Sunny and Karthikesalingam, Alan and Kelly, Christopher J. and King, Dominic and Ledsam, Joseph R. and Melnick, David and Mostofi, Hormuz and Peng, Lily and Reicher, Joshua Jay and Romera-Paredes, Bernardino and Sidebottom, Richard and Suleyman, Mustafa and Tse, Daniel and Young, Kenneth C. and De Fauw, Jeffrey and Shetty, Shravya},
    month = jan,
    year = {2020},
    note = {Publisher: Nature Publishing Group},
    keywords = {Breast cancer, Preclinical research},
    pages = {89--94},
}
@article{rashmi_predicting_2021,
    title = {Predicting the molecular subtype of breast cancer based on mammography and ultrasound findings},
    volume = {28},
    copyright = {Thieme Medical and Scientific Publishers Pvt. Ltd. A-12, 2nd Floor, Sector 2, Noida-201301 UP, India},
    issn = {0971-3026},
    url = {https://www.thieme-connect.de/products/ejournals/abstract/10.4103/ijri.IJRI_78_18},
    doi = {10.4103/ijri.IJRI_78_18},
    abstract = {Aim: To determine the correlation between mammography and ultrasound features of breast cancer with molecular subtypes and to calculate the predictive value of these features. Materials and Method: This is a prospective study of consecutive patients with breast cancer presenting between January 2016 and July 2017, who underwent mammography and/or ultrasound of breast and excision of the breast mass. Patients with contralateral breast mass, metastases, h/o prior cancer treatment, and other malignancies were excluded. On mammography, the presence or absence of microcalcification was noted. On ultrasound examination size, margins, microcalcification, posterior acoustic features, vascularity, and axillary nodes were assessed. Margins were categorized into circumscribed and non-circumscribed. Posterior acoustic features were classified into four categories: shadowing, enhancement, mixed, and no changes. Vascularity was assessed based on Adler's index into grades 0, 1, 2, and 3. Grades 0 and 1 were considered low and 2 and 3 were high. Results: Tumors with non-circumscribed margins and posterior acoustic shadowing were likely to be luminal A or B subtype of breast cancer [odds ratio (JR) 5.78; 95\% confidence interval (CI) 3.68–9.80; P {\textless} 0.0001]. Tumors with non-circumscribed margins, posterior acoustic shadowing, and high vascularity were more likely to be luminal B subtype (JR 2.88; 95\% CI 2–4.14; P- {\textless}0.0001). Tumors with microcalcification and posterior mixed acoustic pattern were strongly associated to be HER2-positive (JR 5.48; 95\% CI 3.06–9.80; P {\textless} 0.0001). Tumors with circumscribed margins and posterior acoustic enhancement were highly suggestive of triple-negative breast cancer (JR 7.06; 95\% CI 4.64–10.73; P {\textless} 0.0001). Conclusion: Microcalcification detected on mammography and certain ultrasound features such as circumscribed or non-circumscribed margins, posterior acoustic features, and vascularity are strongly correlated in predicting the molecular subtypes of breast cancer, and thus may further expand the role of conventional breast imaging.},
    language = {en},
    urldate = {2025-05-19},
    journal = {Indian Journal of Radiology and Imaging},
    author = {Rashmi, S. and Kamala, S. and Murthy, S. Sudha and Kotha, Swapna and Rao, Y. Suhas and Chaudhary, K. Veeraiah},
    month = jul,
    year = {2021},
    note = {Publisher: Thieme Medical and Scientific Publishers Pvt. Ltd.},
    pages = {354--361},
}
@article{goldhirsch_personalizing_2013,
    title = {Personalizing the treatment of women with early breast cancer: highlights of the {St} {Gallen} {International} {Expert} {Consensus} on the {Primary} {Therapy} of {Early} {Breast} {Cancer} 2013},
    volume = {24},
    issn = {0923-7534, 1569-8041},
    shorttitle = {Personalizing the treatment of women with early breast cancer},
    url = {https://www.annalsofoncology.org/article/S0923-7534(19)36964-9/fulltext},
    doi = {10.1093/annonc/mdt303},
    language = {English},
    number = {9},
    urldate = {2025-05-24},
    journal = {Annals of Oncology},
    author = {Goldhirsch, A. and Winer, E. P. and Coates, A. S. and Gelber, R. D. and Piccart-Gebhart, M. and Thürlimann, B. and Senn, H.-J. and Albain, Kathy S. and André, Fabrice and Bergh, Jonas and Bonnefoi, Hervé and Bretel-Morales, Denisse and Burstein, Harold and Cardoso, Fatima and Castiglione-Gertsch, Monica and Coates, Alan S. and Colleoni, Marco and Costa, Alberto and Curigliano, Giuseppe and Davidson, Nancy E. and Leo, Angelo Di and Ejlertsen, Bent and Forbes, John F. and Gelber, Richard D. and Gnant, Michael and Goldhirsch, Aron and Goodwin, Pamela and Goss, Paul E. and Harris, Jay R. and Hayes, Daniel F. and Hudis, Clifford A. and Ingle, James N. and Jassem, Jacek and Jiang, Zefei and Karlsson, Per and Loibl, Sibylle and Morrow, Monica and Namer, Moise and Osborne, C. Kent and Partridge, Ann H. and Penault-Llorca, Frédérique and Perou, Charles M. and Piccart-Gebhart, Martine J. and Pritchard, Kathleen I. and Rutgers, Emiel J. T. and Sedlmayer, Felix and Semiglazov, Vladimir and Shao, Zhi-Ming and Smith, Ian and Thürlimann, Beat and Toi, Masakazu and Tutt, Andrew and Untch, Michael and Viale, Giuseppe and Watanabe, Toru and Wilcken, Nicholas and Winer, Eric P. and Wood, William C.},
    month = sep,
    year = {2013},
    pmid = {23917950},
    note = {Publisher: Elsevier},
    keywords = {St Gallen Consensus, early breast cancer, radiation therapy, subtypes, surgery, systemic adjuvant therapies},
    pages = {2206--2223},
}
@article{mauricio_comparing_2023,
    title = {Comparing {Vision} {Transformers} and {Convolutional} {Neural} {Networks} for {Image} {Classification}: {A} {Literature} {Review}},
    volume = {13},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    issn = {2076-3417},
    shorttitle = {Comparing {Vision} {Transformers} and {Convolutional} {Neural} {Networks} for {Image} {Classification}},
    url = {https://www.mdpi.com/2076-3417/13/9/5521},
    doi = {10.3390/app13095521},
    abstract = {Transformers are models that implement a mechanism of self-attention, individually weighting the importance of each part of the input data. Their use in image classification tasks is still somewhat limited since researchers have so far chosen Convolutional Neural Networks for image classification and transformers were more targeted to Natural Language Processing (NLP) tasks. Therefore, this paper presents a literature review that shows the differences between Vision Transformers (ViT) and Convolutional Neural Networks. The state of the art that used the two architectures for image classification was reviewed and an attempt was made to understand what factors may influence the performance of the two deep learning architectures based on the datasets used, image size, number of target classes (for the classification problems), hardware, and evaluated architectures and top results. The objective of this work is to identify which of the architectures is the best for image classification and under what conditions. This paper also describes the importance of the Multi-Head Attention mechanism for improving the performance of ViT in image classification.},
    language = {en},
    number = {9},
    urldate = {2025-05-25},
    journal = {Applied Sciences},
    author = {Maurício, José and Domingues, Inês and Bernardino, Jorge},
    month = jan,
    year = {2023},
    note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
    keywords = {Vision Transformers (ViT), convolutional neural networks, image classification, multi-head attention, transformers},
    pages = {5521},
}
@misc{who_breast_2024,
    title = {Breast cancer},
    url = {https://www.who.int/news-room/fact-sheets/detail/breast-cancer},
    language = {en},
    urldate = {2025-05-28},
    year = {2024},
}
@misc{seom_cancer_nodate,
    title = {El cáncer en cifras},
    url = {https://seom.org/prensa/el-cancer-en-cifras},
    urldate = {2025-05-28},
}
@misc{cleveland_clinic_breast_2023,
    title = {Breast {Cancer}},
    url = {https://my.clevelandclinic.org/health/diseases/3986-breast-cancer},
    abstract = {Thanks to breast cancer awareness, research and new treatments, more people are living with breast cancer. Read on to find out more.},
    language = {en},
    urldate = {2025-05-28},
    journal = {Cleveland Clinic},
    author = {{Cleveland Clinic}},
    year = {2023},
}
@misc{noauthor_nci_2011,
    type = {{nciAppModulePage}},
    title = {{NCI} {Dictionary} of {Cancer} {Terms} - {NCI}},
    url = {https://www.cancer.gov/publications/dictionaries/cancer-terms/},
    abstract = {NCI's Dictionary of Cancer Terms provides easy-to-understand definitions for words and phrases related to cancer and medicine.},
    language = {en},
    urldate = {2025-05-28},
    month = feb,
    year = {2011},
    note = {Archive Location: nciglobal,ncienterprise},
}
@article{perou_molecular_2000,
    title = {Molecular portraits of human breast tumours},
    volume = {406},
    issn = {0028-0836},
    doi = {10.1038/35021093},
    abstract = {Human breast tumours are diverse in their natural history and in their responsiveness to treatments. Variation in transcriptional programs accounts for much of the biological diversity of human cells and tumours. In each cell, signal transduction and regulatory systems transduce information from the cell's identity to its environmental status, thereby controlling the level of expression of every gene in the genome. Here we have characterized variation in gene expression patterns in a set of 65 surgical specimens of human breast tumours from 42 different individuals, using complementary DNA microarrays representing 8,102 human genes. These patterns provided a distinctive molecular portrait of each tumour. Twenty of the tumours were sampled twice, before and after a 16-week course of doxorubicin chemotherapy, and two tumours were paired with a lymph node metastasis from the same patient. Gene expression patterns in two tumour samples from the same individual were almost always more similar to each other than either was to any other sample. Sets of co-expressed genes were identified for which variation in messenger RNA levels could be related to specific features of physiological variation. The tumours could be classified into subtypes distinguished by pervasive differences in their gene expression patterns.},
    language = {eng},
    number = {6797},
    journal = {Nature},
    author = {Perou, C. M. and Sørlie, T. and Eisen, M. B. and van de Rijn, M. and Jeffrey, S. S. and Rees, C. A. and Pollack, J. R. and Ross, D. T. and Johnsen, H. and Akslen, L. A. and Fluge, O. and Pergamenschikov, A. and Williams, C. and Zhu, S. X. and Lønning, P. E. and Børresen-Dale, A. L. and Brown, P. O. and Botstein, D.},
    month = aug,
    year = {2000},
    pmid = {10963602},
    keywords = {Breast Neoplasms, DNA, Neoplasm, Female, Gene Expression, Gene Expression Profiling, Genes, erbB-2, Humans, Oligonucleotide Array Sequence Analysis, Phenotype, Tumor Cells, Cultured},
    pages = {747--752},
}
@article{sorlie_repeated_2003,
    title = {Repeated observation of breast tumor subtypes in independent gene expression data sets},
    volume = {100},
    url = {https://www.pnas.org/doi/10.1073/pnas.0932692100},
    doi = {10.1073/pnas.0932692100},
    abstract = {Characteristic patterns of gene expression measured by DNA microarrays have been used to classify tumors into clinically relevant subgroups. In this study, we have refined the previously defined subtypes of breast tumors that could be distinguished by their distinct patterns of gene expression. A total of 115 malignant breast tumors were analyzed by hierarchical clustering based on patterns of expression of 534 “intrinsic” genes and shown to subdivide into one basal-like, one ERBB2-overexpressing, two luminal-like, and one normal breast tissue-like subgroup. The genes used for classification were selected based on their similar expression levels between pairs of consecutive samples taken from the same tumor separated by 15 weeks of neoadjuvant treatment. Similar cluster analyses of two published, independent data sets representing different patient cohorts from different laboratories, uncovered some of the same breast cancer subtypes. In the one data set that included information on time to development of distant metastasis, subtypes were associated with significant differences in this clinical feature. By including a group of tumors from BRCA1 carriers in the analysis, we found that this genotype predisposes to the basal tumor subtype. Our results strongly support the idea that many of these breast tumor subtypes represent biologically distinct disease entities.},
    number = {14},
    urldate = {2025-05-29},
    journal = {Proceedings of the National Academy of Sciences},
    author = {Sørlie, Therese and Tibshirani, Robert and Parker, Joel and Hastie, Trevor and Marron, J. S. and Nobel, Andrew and Deng, Shibing and Johnsen, Hilde and Pesich, Robert and Geisler, Stephanie and Demeter, Janos and Perou, Charles M. and Lønning, Per E. and Brown, Patrick O. and Børresen-Dale, Anne-Lise and Botstein, David},
    month = jul,
    year = {2003},
    note = {Publisher: Proceedings of the National Academy of Sciences},
    pages = {8418--8423},
}
@article{lips_breast_2013,
    title = {Breast cancer subtyping by immunohistochemistry and histological grade outperforms breast cancer intrinsic subtypes in predicting neoadjuvant chemotherapy response},
    volume = {140},
    issn = {0167-6806},
    url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3706735/},
    doi = {10.1007/s10549-013-2620-0},
    abstract = {Intrinsic subtypes are widely accepted for the classification of breast cancer. Lacking gene expression data, surrogate classifications based on immunohistochemistry (IHC) have been proposed. A recent St. Gallen consensus meeting recommends to use this “surrogate intrinsic subtypes” for predicting adjuvant chemotherapy resistance, implying that “Surrogate Luminal A” breast cancers should only receive endocrine therapy. In this study we assessed both gene expression based intrinsic subtypes as well as surrogate intrinsic subtypes regarding their power to predict neoadjuvant chemotherapy benefit. Single institution data of 560 breast cancer patients were reviewed. Gene expression data was available for 247 patients. Subtypes were determined on the basis of IHC, Ki67, histological grade, endocrine responsiveness, and gene expression, and were correlated with chemotherapy response and recurrence-free survival. In ER+/HER2− tumors, a high histological grade was the best predictor for chemotherapy benefit, both in terms of pCR (p = 0.004) and recurrence-free survival (p = 0.002). The gene expression based and surrogate intrinsic subtype based on Ki67 had no predictive or prognostic value in ER+/HER2− tumors. Histological grade, ER, PR, and HER2 were the best predictive factors for chemotherapy response in breast cancer. We propose to continue the conventional use of these markers.},
    number = {1},
    urldate = {2025-05-29},
    journal = {Breast Cancer Research and Treatment},
    author = {Lips, E. H. and Mulder, L. and de Ronde, J. J. and Mandjes, I. A. M. and Koolen, B. B. and Wessels, L. F. A. and Rodenhuis, S. and Wesseling, J.},
    year = {2013},
    pmid = {23828499},
    pmcid = {PMC3706735},
    pages = {63--71},
}
@misc{noauthor_bi-rads_2025,
    title = {{BI}-{RADS} {Score}: {Understanding} {Breast} {Imaging} {Results}},
    shorttitle = {{BI}-{RADS} {Score}},
    url = {https://www.healthcentral.com/article/birads-breast-imaging-reporting-and-data-system},
    abstract = {BI-RADS score is a system used to categorize mammogram findings, indicating the likelihood of breast cancer.},
    language = {en},
    urldate = {2025-06-01},
    journal = {HealthCentral},
    month = may,
    year = {2025},
}
@misc{noauthor_stages_nodate,
    title = {Stages of {Breast} {Cancer} {\textbar} {Understand} {Breast} {Cancer} {Staging}},
    url = {https://www.cancer.org/cancer/types/breast-cancer/understanding-a-breast-cancer-diagnosis/stages-of-breast-cancer.html},
    abstract = {When someone is diagnosed with breast cancer, doctors will determine if it has spread. This process is called staging. Learn about what your cancer stage means.},
    language = {en},
    urldate = {2025-06-01},
}
@article{hortobagyi_new_2018,
    title = {New and {Important} {Changes} in the {TNM} {Staging} {System} for {Breast} {Cancer}},
    issn = {1548-8748},
    url = {https://ascopubs.org/doi/10.1200/EDBK_201313},
    doi = {10.1200/EDBK_201313},
    number = {38},
    urldate = {2025-06-01},
    journal = {American Society of Clinical Oncology Educational Book},
    author = {Hortobagyi, Gabriel N. and Edge, Stephen B. and Giuliano, Armando},
    month = may,
    year = {2018},
    note = {Publisher: Wolters Kluwer},
    pages = {457--467},
}
@misc{kashiwada_tompei-cmmd_2025,
    title = {{TOMPEI}-{CMMD} {Dataset}},
    url = {https://doi.org/10.7937/WEZW-BH22},
    doi = {10.7937/WEZW-BH22},
    publisher = {The Cancer Imaging Archive},
    author = {Kashiwada, Y and Takaya, E and Hiroya, M and Matsuda, N and Yashima, T and Kobayashi, T and Tamiya, G and Ueda, T},
    year = {2025},
}
@article{makki_diversity_2015,
    title = {Diversity of {Breast} {Carcinoma}: {Histological} {Subtypes} and {Clinical} {Relevance}},
    volume = {8},
    issn = {1179-5557},
    shorttitle = {Diversity of {Breast} {Carcinoma}},
    url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4689326/},
    doi = {10.4137/CPath.S31563},
    abstract = {Mammary carcinoma is the most common malignant tumor in women, and it is the leading cause of mortality, with an incidence of {\textgreater}1,000,000 cases occurring worldwide annually. It is one of the most common human neoplasms, accounting for approximately one-quarter of all cancers in females worldwide and 27\% of cancers in developed countries with a Western lifestyle. They exhibit a wide scope of morphological features, different immunohistochemical profiles, and unique histopathological subtypes that have specific clinical course and outcome. Breast cancers can be classified into distinct subgroups based on similarities in the gene expression profiles and molecular classification.},
    urldate = {2025-06-03},
    journal = {Clinical Medicine Insights. Pathology},
    author = {Makki, Jaafar},
    month = dec,
    year = {2015},
    pmid = {26740749},
    pmcid = {PMC4689326},
    pages = {23--31},
}
@misc{noauthor_types_nodate,
    title = {Types of {Breast} {Cancer} {\textbar} {About} {Breast} {Cancer}},
    url = {https://www.cancer.org/cancer/types/breast-cancer/about/types-of-breast-cancer.html},
    abstract = {Learn about the different types of breast cancer including the common types of DCIS, invasive ductal carcinoma, and invasive lobular carcinoma.},
    language = {en},
    urldate = {2025-06-03},
}
@incollection{magny_breast_2025,
    address = {Treasure Island (FL)},
    title = {Breast {Imaging} {Reporting} and {Data} {System}},
    copyright = {Copyright © 2025, StatPearls Publishing LLC.},
    url = {http://www.ncbi.nlm.nih.gov/books/NBK459169/},
    abstract = {Breast imaging-reporting and data system (BI-RADS) is a classification system proposed by the American College of Radiology (ACR) in 1986 with the original report released in 1993. The 1980s saw an exponential increase in mammography with the implementation of yearly screening mammograms and overwhelming variation amongst radiology reports. BI-RADS was implemented to standardize risk assessment and quality control for mammography and provide uniformity in the reports for non-radiologist. The first version proposed included the suggested structure for a mammographic report, the lexicon for mammographic imaging findings, and final assessment category with recommendations for management. The ACR used scientific analysis and literature review to create a lexicon of descriptors that had shown to correlate with high predictive values associated with either benign or malignant disease. The second important aspect of the BI-RADS system was the category classification for the overall assessment of the imaging findings. The categorization provides an approximate risk of malignancy to a lesion from essentially zero to greater than 95\%. The categorization and final assessment decreased ambiguity in recommendations. BI-RADS was built to be fluid and change with the adaptation of new techniques and research. Such changes that have occurred are the inclusion of lexicons for ultrasound in 2003 and MRI in 2006. The latest edition is BI-RADS 5 (2013) and included six classifications for lesions.},
    language = {eng},
    urldate = {2025-06-03},
    booktitle = {{StatPearls}},
    publisher = {StatPearls Publishing},
    author = {Magny, Samuel J. and Shikhman, Rachel and Keppke, Ana L.},
    year = {2025},
    pmid = {29083600},
}
@misc{staff_what_2025,
    title = {What {You} {Need} to {Know} {About} {X}-{Ray} in {Mammography} - {Centers} {Urgent} {Care}},
    url = {https://centersurgentcare.net/x-ray-in-mammography/general/, https://centersurgentcare.net/x-ray-in-mammography/general/},
    abstract = {Early detection saves lives—see how x-rays in mammography reveal hidden breast changes long before symptoms appear.},
    language = {en-US},
    urldate = {2025-06-03},
    author = {Staff},
    month = may,
    year = {2025},
    note = {Section: General},
}

@article{iranmakani_review_2020,
    title = {A review of various modalities in breast imaging: technical aspects and clinical outcomes},
    volume = {51},
    issn = {2090-4762},
    shorttitle = {A review of various modalities in breast imaging},
    url = {https://doi.org/10.1186/s43055-020-00175-5},
    doi = {10.1186/s43055-020-00175-5},
    abstract = {Nowadays, breast cancer is the second cause of death after cardiovascular diseases. In general, about one out of eight women (about 12\%) suffer from this disease during their life in the USA and European countries. If breast cancer is detected at an early stage, its survival rate will be very high. Several methods have been introduced to diagnose breast cancer with their clinical advantages and disadvantages.},
    number = {1},
    urldate = {2025-06-01},
    journal = {Egyptian Journal of Radiology and Nuclear Medicine},
    author = {Iranmakani, Sepideh and Mortezazadeh, Tohid and Sajadian, Fakhrossadat and Ghaziani, Mona Fazel and Ghafari, Ali and Khezerloo, Davood and Musa, Ahmed Eleojo},
    month = apr,
    year = {2020},
    keywords = {Breast cancer, MRI, Mammography, Microwave imaging, Nuclear medicine, Optical imaging, Sonography},
    pages = {57},
}
@misc{ltd_mammography_2025,
    title = {Mammography {Market} {Size}, {Share} \& {Opportunities} 2025-2032},
    url = {https://www.coherentmarketinsights.com/market-insight/mammography-market-5425},
    abstract = {Mammography Market is estimated to be valued at USD 2.87 Bn in 2025 and is expected to expand at annual growth rate of 10.4\% , reaching USD 5.74 Bn by 2032.},
    language = {en},
    urldate = {2025-06-03},
    journal = {Coherent Market Insights},
    author = {Ltd, Coherent Market Insights Pvt},
    month = feb,
    year = {2025},
}
@misc{noauthor_mammography_nodate,
    title = {Mammography {Market} {Size} \& {Share} {\textbar} {Industry} {Report}, 2030},
    url = {https://www.grandviewresearch.com/industry-analysis/mammography-market},
    abstract = {The global mammography market size was estimated at USD 2.58 billion in 2024 and is projected to grow at a CAGR of 10.50\% from 2025 to 2030},
    language = {en},
    urldate = {2025-06-03},
}
@misc{noauthor_guide_nodate,
    title = {Guide to {Mammography} {Views} \& {Positioning} {\textbar} {MTMI}},
    url = {https://www.mtmi.net/blog/guide-mammography-views-positioning},
    abstract = {Proper mammographic positioning is essential to the detection and diagnosis of breast cancer. Without properly positioned and exposed images, the radiologist cannot clearly find the presence of abnormalities which would possibly require a biopsy. Skilled, dedicated mammographers must recognize the importance of their role and must always pay close attention to detail so they can produce high-quality, mammograms on behalf of both the patient and the radiologist. This requires ongoing education and a thorough understanding of normal breast anatomy.},
    language = {en},
    urldate = {2025-06-03},
}
@misc{aljarrah_trends_2014,
    title = {Trends in the distribution of breast cancer over time in the southeast of {Scotland} and review of the literature},
    copyright = {© 2019 the authors; licensee ecancermedicalscience. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
    url = {http://ecancer.org/en/journal/article/427-trends-in-the-distribution-of-breast-cancer-over-time-in-the-southeast-of-scotland-and-review-of-the-literature},
    abstract = {Trends in the distribution of breast cancer over time in the southeast of Scotland and review of the literature
    	A Aljarrah1,2 and WR Miller2},
    language = {en},
    urldate = {2025-06-03},
    author = {Aljarrah, A. and Miller, W. R.},
    month = may,
    year = {2014},
    doi = {10.3332/ecancer.2014.427},
}
@misc{noauthor_breast_2015,
    title = {Breast cancer incidence (invasive) statistics},
    url = {https://www.cancerresearchuk.org/health-professional/cancer-statistics/statistics-by-cancer-type/breast-cancer/incidence-invasive},
    abstract = {The latest breast cancer incidence invasive statistics for the UK for Health Professionals. See data for age, trends over time, stage at diagnosis and more.},
    language = {en},
    urldate = {2025-06-03},
    journal = {Cancer Research UK},
    month = may,
    year = {2015},
}
@misc{imaging_introduction_2022,
    title = {Introduction to {Mammography}: {The} {Basics}},
    shorttitle = {Introduction to {Mammography}},
    url = {https://clinicalpub.com/introduction-to-mammography-the-basics/},
    abstract = {Overview This chapter is a basic introduction to the fundamentals of mammography, including standard and special views, technical adequacy, and normal anatomy . Breast imaging is integral to the diagnosis and evaluation of breast cancer and other breast pathologies. While ultrasound and magnetic resonance radiology (MRI) also play important roles, mammography is often considered the […]},
    language = {en-US},
    urldate = {2025-06-03},
    journal = {Clinical Tree},
    author = {Imaging, Breast},
    month = dec,
    year = {2022},
}
@article{gokhale_ultrasound_2009,
    title = {Ultrasound characterization of breast masses},
    volume = {19},
    issn = {0971-3026},
    url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2766883/},
    doi = {10.4103/0971-3026.54878},
    abstract = {A lump in the breast is a cause of great concern. High frequency, high-resolution USG helps in its evaluation. This is exemplified in women with dense breast tissue where USG is useful in detecting small breast cancers that are not seen on mammography. Several studies in the past have addressed the issue of differentiating benign from malignant lesions in the breast. The American College of Radiology has also brought out a BIRADS-US classification system for categorizing focal breast lesions.},
    number = {3},
    urldate = {2025-06-03},
    journal = {The Indian Journal of Radiology \& Imaging},
    author = {Gokhale, Sudheer},
    month = aug,
    year = {2009},
    pmid = {19881096},
    pmcid = {PMC2766883},
    pages = {242--247},
}
@misc{noauthor_breast_nodate,
    title = {Breast {Ultrasound} ({Sonogram})},
    url = {https://densebreast-info.org/screening-technologies/breast-ultrasound/},
    language = {en},
    urldate = {2025-06-03},
    journal = {DenseBreast-info, Inc.},
}
@misc{radswiki_breast_nodate,
    title = {Breast {MRI} {\textbar} {Radiology} {Reference} {Article} {\textbar} {Radiopaedia}.org},
    url = {https://radiopaedia.org/articles/breast-mri},
    abstract = {Breast MRI is the most sensitive method ({\textgreater}90\%) for the detection of breast cancer. Its role in diagnosis and management continues to evolve 13.
Terminology
Dynamic contrast-enhanced (DCE)-MRI provides information about the morphology and functi...},
    language = {en-US},
    urldate = {2025-06-03},
    journal = {Radiopaedia},
    author = {Radswiki, The},
    doi = {10.53347/rID-12182},
}
@misc{noauthor_technical_nodate,
    title = {Technical guidelines for {MRI} for the surveillance of women at higher risk of developing breast cancer},
    url = {https://www.gov.uk/government/publications/nhs-breast-screening-using-mri-with-higher-risk-women/technical-guidelines-for-mri-for-the-surveillance-of-women-at-higher-risk-of-developing-breast-cancer},
    language = {en},
    urldate = {2025-06-03},
    journal = {GOV.UK},
}

@misc{nih_definition_2011,
    type = {Definition of {MRI}},
    title = {Definition of {MRI} - {NCI} {Dictionary} of {Cancer} {Terms} - {NCI}},
    shorttitle = {Definition of {MRI}},
    url = {https://www.cancer.gov/publications/dictionaries/cancer-terms/def/mri},
    abstract = {NCI's Dictionary of Cancer Terms provides easy-to-understand definitions for words and phrases related to cancer and medicine.},
    language = {en},
    urldate = {2025-06-03},
    journal = {Definition of MRI},
    author = {{NIH}},
    month = feb,
    year = {2011},
    note = {Archive Location: nciglobal,ncienterprise},
}
@misc{nihDefinitionMammogramNCI2011,
    type = {{nciAppModulePage}},
    title = {Definition of mammogram - {NCI} {Dictionary} of {Cancer} {Terms} - {NCI}},
    shorttitle = {Definition of {Mammogram}},
    url = {https://www.cancer.gov/publications/dictionaries/cancer-terms/def/mammogram},
    abstract = {NCI's Dictionary of Cancer Terms provides easy-to-understand definitions for words and phrases related to cancer and medicine.},
    language = {en},
    urldate = {2025-06-03},
    journal = {Definition of Mammogram},
    author = {{NIH}},
    month = feb,
    year = {2011},
    note = {Archive Location: nciglobal,ncienterprise},
}
@misc{macauley_start--finish_2022,
    title = {A {Start}-{To}-{Finish} {Guide} {To} {Performing} {A} {Breast} {Ultrasound}},
    url = {https://sonographyminutes.com/a-start-to-finish-guide-to-performing-a-breast-ultrasound/},
    abstract = {If you’re new to Breast Ultrasound it can feel overwhelming, but it doesn’t have to be! This step-by-step Breast Ultrasound roadmap will help you conquer this exam, and ensure that you don’t miss anything important along the way. Have you ever faced an Ultrasound exam that you’ve never done before and felt completely lost? As … Continue reading A Start-To-Finish Guide To Performing A Breast Ultrasound},
    language = {en-US},
    urldate = {2025-06-03},
    journal = {Sonography Minutes},
    author = {Macauley, Michelle},
    month = jan,
    year = {2022},
}
@misc{noauthor_cancer_2010,
    type = {{pdqCancerInfoSummary}},
    title = {Cancer {Screening} {Overview} - {NCI}},
    url = {https://www.cancer.gov/about-cancer/screening/patient-screening-overview-pdq},
    abstract = {Cancer screening means looking for cancer before symptoms appear, when cancer may be easier to treat. Screening tests can help reduce the risk of dying from some cancers, but all tests have potential risks, too. Learn more about cancer screening and available tests in this expert-reviewed summary.},
    language = {en},
    urldate = {2025-06-03},
    month = jan,
    year = {2010},
    note = {Archive Location: nciglobal,ncienterprise},
}
@misc{cancer_que_2023,
    title = {Qué es un cribado cáncer de mama - {Blog} {Contra} el {Cáncer}},
    url = {https://blog.contraelcancer.es/cribado-cancer-mama/},
    abstract = {Entra en el blog de la Asociación Española Contra el Cáncer y descubre qué es un cribado de cáncer de mama. ¡Entra ahora y obtén todas tus respuestas!},
    language = {es},
    urldate = {2025-06-03},
    journal = {Blog de la Asociación Española Contra el Cáncer},
    author = {Cáncer, Asociación Española Contra el},
    month = oct,
    year = {2023},
}
@misc{noauthor_ministerio_nodate,
    title = {Ministerio de {Sanidad} - Áreas - {INFORMACION} {GENERAL} - {CRIBADO} {CANCER} - {CANCER} {DE} {MAMA}},
    url = {https://www.sanidad.gob.es/areas/promocionPrevencion/cribado/cribadoCancer/cancerMama/infoGeneral.htm},
    urldate = {2025-06-03},
}
@misc{noauthor_map_nodate,
    title = {Map: {Screening} {Guidelines} by {Country}},
    shorttitle = {Map},
    url = {https://densebreast-info.org/europe/european-screening-guidelines/map-screening-guidelines/},
    language = {en},
    urldate = {2025-06-03},
    journal = {DenseBreast-info, Inc.},
}
@misc{DefinitionBiopsyNCI2011,
    type = {{nciAppModulePage}},
    title = {Definition of biopsy - {NCI} {Dictionary} of {Cancer} {Terms} - {NCI}},
    url = {https://www.cancer.gov/publications/dictionaries/cancer-terms/def/biopsy},
    abstract = {NCI's Dictionary of Cancer Terms provides easy-to-understand definitions for words and phrases related to cancer and medicine.},
    language = {en},
    urldate = {2025-06-03},
    month = feb,
    year = {2011},
    note = {Archive Location: nciglobal,ncienterprise},
}
@misc{noauthor_fine_nodate,
    title = {Fine {Needle} {Aspiration} ({FNA}) of the {Breast}},
    url = {https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-biopsy/fine-needle-aspiration-biopsy-of-the-breast.html},
    abstract = {In an FNA of the breast, a thin needle is used to get a small sample of tissue or fluid to check for cancer cells. Learn more about this type of biopsy here.},
    language = {en},
    urldate = {2025-06-04},
}
@article{jeong_analysis_2020,
    title = {Analysis of the molecular subtypes of preoperative core needle biopsy and surgical specimens in invasive breast cancer},
    volume = {54},
    issn = {2383-7837},
    url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6986971/},
    doi = {10.4132/jptm.2019.10.14},
    abstract = {Background
Accurate molecular classification of breast core needle biopsy (CNB) tissue is important for determining neoadjuvant systemic therapies for invasive breast cancer. The researchers aimed to evaluate the concordance rate (CR) of molecular subtypes between CNBs and surgical specimens.
Methods
This study was conducted with invasive breast cancer patients who underwent surgery after CNB at Seoul St. Mary’s Hospital between December 2014 and December 2017. Estrogen receptor (ER), progesterone receptor (PR), human epidermal growth factor receptor 2 (HER2), and Ki67 were analyzed using immunohistochemistry. ER and PR were evaluated by Allred score (0–8). HER2 was graded from 0 to +3, and all 2+ cases were reflex tested with silver in situ hybridization. The labeling index of Ki67 was counted by either manual scoring or digital image analysis. Molecular subtypes were classified using the above surrogate markers.
Results
In total, 629 patients were evaluated. The CRs of ER, PR, HER2, and Ki67 were 96.5\% (kappa, 0.883; p{\textless}.001), 93.0\% (kappa, 0.824; p{\textless}.001), 99.7\% (kappa, 0.988; p{\textless}.001), and 78.7\% (kappa, 0.577; p{\textless}.001), respectively. Digital image analysis of Ki67 in CNB showed better concordance with Ki67 in surgical specimens (CR, 82.3\%; kappa, 0.639 for digital image analysis vs. CR, 76.2\%; kappa, 0.534 for manual counting). The CRs of luminal A, luminal B, HER2, and triple negative types were 89.0\%, 70.0\%, 82.9\%, and 77.2\%, respectively. 
Conclusions
CNB was reasonably accurate for determining ER, PR, HER2, Ki67, and molecular subtypes. Using digital image analysis for Ki67 in CNB produced more accurate molecular classifications.},
    number = {1},
    urldate = {2025-06-04},
    journal = {Journal of Pathology and Translational Medicine},
    author = {Jeong, Ye Sul and Kang, Jun and Lee, Jieun and Yoo, Tae-Kyung and Kim, Sung Hun and Lee, Ahwon},
    month = jan,
    year = {2020},
    pmid = {31718121},
    pmcid = {PMC6986971},
    pages = {87--94},
}
@misc{CoreNeedleBiopsy,
    title = {Core {Needle} {Biopsy} of the {Breast} {\textbar} {Stereotactic} {Breast} {Biopsy}},
    url = {https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-biopsy/core-needle-biopsy-of-the-breast.html},
    abstract = {Core needle biopsy (CNB) uses a hollow needle to remove pieces of breast tissue to check for cancer cells. Learn about the types of CNB \& what to expect.},
    language = {en},
    urldate = {2025-06-04},
}
@article{park_vacuum-assisted_2014,
    title = {Vacuum-assisted breast biopsy for breast cancer},
    volume = {3},
    issn = {2227-8575, 2227-684X},
    url = {https://gs.amegroups.org/article/view/3687},
    doi = {10.3978/j.issn.2227-684X.2014.02.03},
    abstract = {Vacuum-assisted breast biopsy for breast cancer},
    language = {en},
    number = {2},
    urldate = {2025-06-04},
    journal = {Gland Surgery},
    author = {Park, Hai-Lin and Hong, Jisun},
    month = may,
    year = {2014},
    note = {Number: 2
Publisher: AME Publishing Company},
    pages = {12027--12127},
}
@article{silva_breast_2023,
    title = {Breast biopsy techniques in a global setting—clinical practice review},
    volume = {4},
    issn = {2218-6778},
    url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11093018/},
    doi = {10.21037/tbcr-23-12},
    abstract = {Breast cancer is a disease of global concern, regardless of economic status. A significant disparity in breast cancer care between low- and high-income countries is not unexpected, but consideration can be given to particular aspects of therapy to allow as much equitability as possible. One of these aspects involves biopsy of breast lesions. With available resources, management in developed countries focuses on dealing with screening and image-detected lesions. In such circumstances, advanced percutaneous biopsy techniques are utilized liberally. However, where resources are less forthcoming for mammographic screening, women frequently present with symptomatic, palpable and larger tumours. This scenario behooves the clinician to modify treatment approaches and yet use cost-effective management strategies. It is essential that thought is applied to breast biopsy technique used where there is cost-consciousness as it significantly influences subsequent therapy. Less expensive strategies like fine needle aspiration cytology (FNAC) and core needle biopsy (CNB), when performed with particular attention to technique, handling, transportation and preparation of biopsy specimens allows a high level of accuracy and provides adequate information for the next steps in treatment. This mini-review discusses the variation in biopsy approaches among lower and higher income areas and offers suggestions for appropriate breast biopsy strategies in resource-limited countries.},
    urldate = {2025-06-04},
    journal = {Translational Breast Cancer Research},
    author = {Silva, Edibaldo and Meschter, Steven and Tan, Mona P.},
    month = apr,
    year = {2023},
    pmid = {38751462},
    pmcid = {PMC11093018},
    pages = {14},
}
@misc{colestrykerWhatArtificialIntelligence2024,
    title = {What {Is} {Artificial} {Intelligence} ({AI})? {\textbar} {IBM}},
    shorttitle = {What {Is} {Artificial} {Intelligence} ({AI})?},
    url = {https://www.ibm.com/think/topics/artificial-intelligence},
    abstract = {Artificial intelligence (AI) is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision-making, creativity and autonomy.},
    language = {en},
    urldate = {2025-06-04},
    author = {{Cole Stryker} and {Eda Kavlakoglu}},
    month = aug,
    year = {2024},
}
@misc{filipsson_evolution_2024,
    title = {The {Evolution} of {AI}: {Tracing} its {Roots} and {Milestones}},
    shorttitle = {The {Evolution} of {AI}},
    url = {https://redresscompliance.com/the-evolution-of-ai-tracing-its-roots-and-milestones/},
    abstract = {Discover the Evolution of AI: From rule-based systems to advanced NLP and computer vision. Explore the societal impacts and ethical challenges of AI.},
    language = {en-US},
    urldate = {2025-06-04},
    author = {Filipsson, Fredrik},
    month = jan,
    year = {2024},
}
@misc{noauthor_what_nodate,
    title = {What is machine learning? {Understanding} types \& applications - {Spiceworks}},
    shorttitle = {What is machine learning?},
    url = {https://www.spiceworks.com/tech/artificial-intelligence/articles/what-is-ml/},
    abstract = {Machine learning is the science of computer algorithms that help machines learn and improve from data analysis without explicit programming.},
    language = {en-US},
    urldate = {2025-06-04},
    journal = {Spiceworks Inc},
}
@article{malik_credit_2024,
    title = {Credit {Risk} {Assessment} and {Fraud} {Detection} in {Financial} {Transactions} {Using} {Machine} {Learning}},
    volume = {20},
    copyright = {https://creativecommons.org/licenses/by-nd/4.0},
    issn = {1112-5209},
    url = {https://journal.esrgroups.org/jes/article/view/1807},
    doi = {10.52783/jes.1807},
    abstract = {Credit risk assessment and fraud detection are crucial tasks in the financial industry, vital to preserving financial organizations' legitimacy and sustainability. Traditional methods often fall short in accurately assessing risk and detecting fraudulent activities in a timely manner. In recent years, machine learning has emerged as a powerful tool for enhancing these processes, leveraging great dimensions of transactional statistics and superior algos for making more informed decisions. This research paper explores the usage of ML techniques in credit risk assessment and fraud detection within financial transactions.
The paper begins with an overview of the importance of accurate risk assessment and fraud detection in financial transactions and introduces the role of machine learning in addressing these challenges. A comprehensive literature review is conducted to analyze existing methodologies, algorithms, and research trends in the field. Data acquisition and preprocessing techniques are discussed, emphasizing the importance of clean and relevant data for model training. Feature engineering strategies are explored to extract meaningful information from financial transaction data and enhance the predictive capabilities of machine learning models.
Various machine learning algorithms suitable for credit risk assessment and fraud detection are examined, including LR, SVMs, RF, DTs and DNNs. The efficacy of these techniques is evaluated by discussing model metrics for assessment and ensemble approaches for boosting efficiency, with a focus on metrics such as accuracy, precision, recall, and ROC-AUC.
The paper presents case studies and experimental results illustrating the application of machine learning models in real-world scenarios, highlighting their effectiveness in improving risk assessment and fraud detection processes. Additionally, difficulties such as imbalanced datasets, comprehensibility of the model and adherence to regulations are discussed, along with potential research directions and future trends in the field.
In conclusion, this research emphasizes the transformative potential of machine learning in credit risk assessment and fraud detection within financial transactions. By leveraging advanced algorithms and data-driven approaches, financial institutions can enhance their decision-making processes, mitigate risks, and safeguard against fraudulent activities, ultimately contributing to a more secure and resilient financial ecosystem.},
    language = {en},
    number = {3s},
    urldate = {2025-06-04},
    journal = {Journal of Electrical Systems},
    author = {Malik, Pankaj and Chourasia, Ankita and Pandit, Rakesh and Bawane, Sheetal and Surana, Jayesh},
    month = mar,
    year = {2024},
    note = {Number: 3s},
    keywords = {ROC-AUC., financial ecosystem, fraudulent, secure},
    pages = {2061--2069},
}
@misc{noauthor_machine_nodate,
    title = {Machine learning in healthcare: {Uses}, benefits and pioneers in the field},
    shorttitle = {Machine learning in healthcare},
    url = {https://eithealth.eu/news-article/machine-learning-in-healthcare-uses-benefits-and-pioneers-in-the-field/},
    abstract = {Explore the transformative impact of machine learning in healthcare, from disease diagnosis to personalised treatment plans.},
    language = {en-US},
    urldate = {2025-06-04},
    journal = {EIT Health},
}
@misc{holdsworthWhatDeepLearning2024,
    title = {What {Is} {Deep} {Learning}? {\textbar} {IBM}},
    shorttitle = {What {Is} {Deep} {Learning}?},
    url = {https://www.ibm.com/think/topics/deep-learning},
    abstract = {Deep learning is a subset of machine learning that uses multilayered neural networks, to simulate the complex decision-making power of the human brain.},
    language = {en},
    urldate = {2025-06-04},
    author = {Holdsworth, Jim and Scapicchio, Mark},
    month = jun,
    year = {2024},
}
@article{turing_icomputing_1950,
    title = {I.—{COMPUTING} {MACHINERY} {AND} {INTELLIGENCE}},
    volume = {LIX},
    issn = {0026-4423},
    url = {https://doi.org/10.1093/mind/LIX.236.433},
    doi = {10.1093/mind/LIX.236.433},
    number = {236},
    urldate = {2025-06-04},
    journal = {Mind},
    author = {TURING, A. M.},
    month = oct,
    year = {1950},
    pages = {433--460},
}
@article{miotto_deep_2017,
    title = {Deep learning for healthcare: review, opportunities and challenges},
    volume = {19},
    issn = {1467-5463},
    shorttitle = {Deep learning for healthcare},
    url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6455466/},
    doi = {10.1093/bib/bbx044},
    abstract = {Gaining knowledge and actionable insights from complex, high-dimensional and heterogeneous biomedical data remains a key challenge in transforming health care. Various types of data have been emerging in modern biomedical research, including electronic health records, imaging, -omics, sensor data and text, which are complex, heterogeneous, poorly annotated and generally unstructured. Traditional data mining and statistical learning approaches typically need to first perform feature engineering to obtain effective and more robust features from those data, and then build prediction or clustering models on top of them. There are lots of challenges on both steps in a scenario of complicated data and lacking of sufficient domain knowledge. The latest advances in deep learning technologies provide new effective paradigms to obtain end-to-end learning models from complex data. In this article, we review the recent literature on applying deep learning technologies to advance the health care domain. Based on the analyzed work, we suggest that deep learning approaches could be the vehicle for translating big biomedical data into improved human health. However, we also note limitations and needs for improved methods development and applications, especially in terms of ease-of-understanding for domain experts and citizen scientists. We discuss such challenges and suggest developing holistic and meaningful interpretable architectures to bridge deep learning models and human interpretability.},
    number = {6},
    urldate = {2025-06-04},
    journal = {Briefings in Bioinformatics},
    author = {Miotto, Riccardo and Wang, Fei and Wang, Shuang and Jiang, Xiaoqian and Dudley, Joel T},
    month = may,
    year = {2017},
    pmid = {28481991},
    pmcid = {PMC6455466},
    pages = {1236--1246},
}
@misc{nasaWhatArtificialIntelligence,
    title = {What is {Artificial} {Intelligence}? - {NASA}},
    shorttitle = {What is {Artificial} {Intelligence}?},
    url = {https://www.nasa.gov/what-is-artificial-intelligence/},
    abstract = {Artificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc.},
    language = {en-US},
    urldate = {2025-06-04},
    author = {{NASA}},
}
@article{jiang_supervised_2020,
    title = {Supervised machine learning: {A} brief primer},
    volume = {51},
    issn = {0005-7894},
    shorttitle = {Supervised machine learning},
    url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7431677/},
    doi = {10.1016/j.beth.2020.05.002},
    abstract = {Machine learning is increasingly used in mental health research and has the potential to advance our understanding of how to characterize, predict, and treat mental disorders and associated adverse health outcomes (e.g., suicidal behavior). Machine learning offers new tools to overcome challenges for which traditional statistical methods are not well-suited. This manuscript provides an overview of machine learning with a specific focus on supervised learning (i.e., methods that are designed to predict or classify an outcome of interest). Several common supervised learning methods are described, along with applied examples from the published literature. We also provide an overview of supervised learning model building, validation, and performance evaluation. Finally, challenges in creating robust and generalizable machine learning algorithms are discussed.},
    number = {5},
    urldate = {2025-06-04},
    journal = {Behavior therapy},
    author = {Jiang, Tammy and Gradus, Jaimie L. and Rosellini, Anthony J.},
    month = sep,
    year = {2020},
    pmid = {32800297},
    pmcid = {PMC7431677},
    pages = {675--687},
}
@misc{noauthor_unsupervised_nodate,
    title = {Unsupervised {Learning} - an overview {\textbar} {ScienceDirect} {Topics}},
    url = {https://www.sciencedirect.com/topics/computer-science/unsupervised-learning},
    urldate = {2025-06-04},
}
@misc{ghasemi_introduction_2024,
    title = {Introduction to {Reinforcement} {Learning}},
    url = {http://arxiv.org/abs/2408.07712},
    doi = {10.48550/arXiv.2408.07712},
    abstract = {Reinforcement Learning (RL), a subfield of Artificial Intelligence (AI), focuses on training agents to make decisions by interacting with their environment to maximize cumulative rewards. This paper provides an overview of RL, covering its core concepts, methodologies, and resources for further learning. It offers a thorough explanation of fundamental components such as states, actions, policies, and reward signals, ensuring readers develop a solid foundational understanding. Additionally, the paper presents a variety of RL algorithms, categorized based on the key factors such as model-free, model-based, value-based, policy-based, and other key factors. Resources for learning and implementing RL, such as books, courses, and online communities are also provided. By offering a clear, structured introduction, this paper aims to simplify the complexities of RL for beginners, providing a straightforward pathway to understanding.},
    urldate = {2025-06-04},
    publisher = {arXiv},
    author = {Ghasemi, Majid and Ebrahimi, Dariush},
    month = dec,
    year = {2024},
    note = {arXiv:2408.07712 [cs]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}
@article{lecun_gradient-based_1998,
    title = {Gradient-based learning applied to document recognition},
    volume = {86},
    issn = {1558-2256},
    url = {https://ieeexplore.ieee.org/document/726791/authors},
    doi = {10.1109/5.726791},
    abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
    number = {11},
    urldate = {2025-06-04},
    journal = {Proceedings of the IEEE},
    author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
    month = nov,
    year = {1998},
    keywords = {Character recognition, Feature extraction, Hidden Markov models, Machine learning, Multi-layer neural network, Neural networks, Optical character recognition software, Optical computing, Pattern recognition, Principal component analysis},
    pages = {2278--2324},
}
@inproceedings{NIPS2012_c399862d,
    title = {{ImageNet} classification with deep convolutional neural networks},
    volume = {25},
    url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
    booktitle = {Advances in neural information processing systems},
    publisher = {Curran Associates, Inc.},
    author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
    editor = {Pereira, F. and Burges, C.J. and Bottou, L. and Weinberger, K.Q.},
    year = {2012},
}
@misc{noauthor_what_2021,
    title = {What are {Convolutional} {Neural} {Networks}? {\textbar} {IBM}},
    shorttitle = {What are {Convolutional} {Neural} {Networks}?},
    url = {https://www.ibm.com/think/topics/convolutional-neural-networks},
    abstract = {Convolutional neural networks use three-dimensional data to for image classification and object recognition tasks.},
    language = {en},
    urldate = {2025-06-04},
    month = oct,
    year = {2021},
}
@misc{langActivationFunctionsNeural2024,
    title = {Activation {Functions} in {Neural} {Networks}: {How} to {Choose} the {Right} {One}},
    shorttitle = {Activation {Functions} in {Neural} {Networks}},
    url = {https://towardsdatascience.com/activation-functions-in-neural-networks-how-to-choose-the-right-one-cb20414c04e5/},
    abstract = {Introduction to activation functions and an overview of the most famous functions},
    language = {en-US},
    urldate = {2025-06-04},
    journal = {Towards Data Science},
    author = {Lang, Niklas},
    month = dec,
    year = {2024},
}
@misc{wachtelUnderstandingActivationFunctions2021,
    title = {Understanding {Activation} {Functions} {\textbar} {Data} {Science} for the {Rest} of {Us}},
    url = {https://medium.com/analytics-vidhya/understanding-activation-functions-data-science-for-the-rest-of-us-b652048a064f},
    abstract = {A bite-size introduction to activation functions for those new to neural nets and/or who hate math…},
    language = {en},
    urldate = {2025-06-04},
    journal = {Analytics Vidhya},
    author = {Wachtel, Ben},
    month = jun,
    year = {2021},
}
@misc{brownlee_gentle_2019,
    title = {A {Gentle} {Introduction} to {Pooling} {Layers} for {Convolutional} {Neural} {Networks}},
    url = {https://www.machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/},
    abstract = {Convolutional layers in a convolutional neural network summarize the presence of features in an input image. A problem with the output feature maps is that they are sensitive to the location of the features in the input. One approach to address this sensitivity is to down sample the feature maps. This has the effect of […]},
    language = {en-US},
    urldate = {2025-06-04},
    journal = {MachineLearningMastery.com},
    author = {Brownlee, Jason},
    month = apr,
    year = {2019},
}
@misc{SkinLesionClassification,
    title = {Skin {Lesion} {Classification} {Using} {Deep} {Neural} {Network}},
    url = {https://www.researchgate.net/publication/337336341_Skin_Lesion_Classification_Using_Deep_Neural_Network},
    abstract = {PDF {\textbar} This paper reports the methods and techniques we have developed for classify dermoscopic images (task 1) of the ISIC 2019 challenge dataset for... {\textbar} Find, read and cite all the research you need on ResearchGate},
    language = {en},
    urldate = {2025-06-04},
    journal = {ResearchGate},
    doi = {10.48550/arXiv.1911.07817},
}
@misc{noauthor_fully_nodate,
    title = {Fully {Connected} {Layer} vs. {Convolutional} {Layer}: {Explained}},
    shorttitle = {Fully {Connected} {Layer} vs. {Convolutional} {Layer}},
    url = {https://builtin.com/machine-learning/fully-connected-layer},
    abstract = {A fully connected layer is a neural network layer where each input node is connected to each output node. In a convolutional layer, not all nodes are connected. Here’s what you need to know.},
    language = {en},
    urldate = {2025-06-04},
    journal = {Built In},
}
@misc{noauthor_convolutional_nodate,
    title = {Convolutional {Neural} {Networks} ({CNN}) {Overview}},
    url = {https://encord.com/blog/convolutional-neural-networks-explained/},
    abstract = {Convolutional Neural Networks (CNNs) are a powerful tool for image analysis that can be used for tasks such as image classification, object dete},
    language = {en-GB},
    urldate = {2025-06-04},
}
@misc{bergmann_what_2024,
    title = {What is {Backpropagation}? {\textbar} {IBM}},
    shorttitle = {What is {Backpropagation}?},
    url = {https://www.ibm.com/think/topics/backpropagation},
    abstract = {Backpropagation is a machine learning algorithm for training neural networks by using the chain rule to compute how network weights contribute to a loss function.},
    language = {en},
    urldate = {2025-06-05},
    author = {Bergmann, Dave and Stryker, Cole},
    month = nov,
    year = {2024},
}
@article{jaamour_divide_2023,
    title = {A divide and conquer approach to maximise deep learning mammography classification accuracies},
    volume = {18},
    issn = {1932-6203},
    url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0280841},
    doi = {10.1371/journal.pone.0280841},
    abstract = {Breast cancer claims 11,400 lives on average every year in the UK, making it one of the deadliest diseases. Mammography is the gold standard for detecting early signs of breast cancer, which can help cure the disease during its early stages. However, incorrect mammography diagnoses are common and may harm patients through unnecessary treatments and operations (or a lack of treatment). Therefore, systems that can learn to detect breast cancer on their own could help reduce the number of incorrect interpretations and missed cases. Various deep learning techniques, which can be used to implement a system that learns how to detect instances of breast cancer in mammograms, are explored throughout this paper. Convolution Neural Networks (CNNs) are used as part of a pipeline based on deep learning techniques. A divide and conquer approach is followed to analyse the effects on performance and efficiency when utilising diverse deep learning techniques such as varying network architectures (VGG19, ResNet50, InceptionV3, DenseNet121, MobileNetV2), class weights, input sizes, image ratios, pre-processing techniques, transfer learning, dropout rates, and types of mammogram projections. This approach serves as a starting point for model development of mammography classification tasks. Practitioners can benefit from this work by using the divide and conquer results to select the most suitable deep learning techniques for their case out-of-the-box, thus reducing the need for extensive exploratory experimentation. Multiple techniques are found to provide accuracy gains relative to a general baseline (VGG19 model using uncropped 512 × 512 pixels input images with a dropout rate of 0.2 and a learning rate of 1 × 10−3) on the Curated Breast Imaging Subset of DDSM (CBIS-DDSM) dataset. These techniques involve transfer learning pre-trained ImagetNet weights to a MobileNetV2 architecture, with pre-trained weights from a binarised version of the mini Mammography Image Analysis Society (mini-MIAS) dataset applied to the fully connected layers of the model, coupled with using weights to alleviate class imbalance, and splitting CBIS-DDSM samples between images of masses and calcifications. Using these techniques, a 5.6\% gain in accuracy over the baseline model was accomplished. Other deep learning techniques from the divide and conquer approach, such as larger image sizes, do not yield increased accuracies without the use of image pre-processing techniques such as Gaussian filtering, histogram equalisation and input cropping.},
    language = {en},
    number = {5},
    urldate = {2025-06-05},
    journal = {PLOS ONE},
    author = {Jaamour, Adam and Myles, Craig and Patel, Ashay and Chen, Shuen-Jen and McMillan, Lewis and Harris-Birtill, David},
    year = {2023},
    note = {Publisher: Public Library of Science},
    keywords = {Breast cancer, Calcification, Cancer detection and diagnosis, Deep learning, Imaging techniques, Machine learning, Malignant tumors, Mammography},
    pages = {e0280841},
}
@misc{he_deep_2015,
    title = {Deep {Residual} {Learning} for {Image} {Recognition}},
    url = {http://arxiv.org/abs/1512.03385},
    doi = {10.48550/arXiv.1512.03385},
    abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
    urldate = {2025-06-05},
    publisher = {arXiv},
    author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
    month = dec,
    year = {2015},
    note = {arXiv:1512.03385 [cs]},
    keywords = {Computer Science - Computer Vision and Pattern Recognition},
}
@misc{simonyanVeryDeepConvolutional,
    title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
    url = {https://arxiv.org/abs/1409.1556},
    urldate = {2025-06-05},
    author = {Simonyan, Karen and Zisserman, Andrew},
}