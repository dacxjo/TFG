
@misc{vaswani_attention_2023,
    title = {Attention {Is} {All} {You} {Need}},
    url = {http://arxiv.org/abs/1706.03762},
    doi = {10.48550/arXiv.1706.03762},
    abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
    language = {en},
    urldate = {2025-03-07},
    publisher = {arXiv},
    author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
    month = aug,
    year = {2023},
    note = {arXiv:1706.03762 [cs]},
    keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}
@article{kim_global_2025,
    title = {Global patterns and trends in breast cancer incidence and mortality across 185 countries},
    issn = {1078-8956, 1546-170X},
    url = {https://www.nature.com/articles/s41591-025-03502-3},
    doi = {10.1038/s41591-025-03502-3},
    language = {en},
    urldate = {2025-03-08},
    journal = {Nature Medicine},
    author = {Kim, Joanne and Harper, Andrew and McCormack, Valerie and Sung, Hyuna and Houssami, Nehmat and Morgan, Eileen and Mutebi, Miriam and Garvey, Gail and Soerjomataram, Isabelle and Fidler-Benaoudia, Miranda M.},
    month = feb,
    year = {2025},
}

@article{harnessing_2024,
author = {Wang, Yun and Bu, Na and Luan, Xiao-fei and Song, Qian-qian and Ma, Ba-Fang and Hao, Wenhui and Yan, Jing-jing and Wang, Li and Zheng, Xiao-ling and Maimaitiyiming, Yasen},
year = {2024},
month = {03},
pages = {},
title = {Harnessing the potential of long non-coding RNAs in breast cancer: from etiology to treatment resistance and clinical applications},
volume = {14},
journal = {Frontiers in Oncology},
doi = {10.3389/fonc.2024.1337579}
}

@misc{iarc2025press,
  author       = {International Agency for Research on Cancer},
  title        = {Breast cancer cases and deaths are projected to rise globally},
  howpublished = {Press Release No. 361, 24 February 2025},
  year         = {2025},
  institution  = {IARC},
  address      = {Lyon, France},
  url          = {https://www.iarc.who.int/wp-content/uploads/2025/02/pr361_E.pdf}
}
@article{wang_early_2017,
    title = {Early {Diagnosis} of {Breast} {Cancer}},
    volume = {17},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    issn = {1424-8220},
    url = {https://www.mdpi.com/1424-8220/17/7/1572},
    doi = {10.3390/s17071572},
    abstract = {Early-stage cancer detection could reduce breast cancer death rates significantly in the long-term. The most critical point for best prognosis is to identify early-stage cancer cells. Investigators have studied many breast diagnostic approaches, including mammography, magnetic resonance imaging, ultrasound, computerized tomography, positron emission tomography and biopsy. However, these techniques have some limitations such as being expensive, time consuming and not suitable for young women. Developing a high-sensitive and rapid early-stage breast cancer diagnostic method is urgent. In recent years, investigators have paid their attention in the development of biosensors to detect breast cancer using different biomarkers. Apart from biosensors and biomarkers, microwave imaging techniques have also been intensely studied as a promising diagnostic tool for rapid and cost-effective early-stage breast cancer detection. This paper aims to provide an overview on recent important achievements in breast screening methods (particularly on microwave imaging) and breast biomarkers along with biosensors for rapidly diagnosing breast cancer.},
    language = {en},
    number = {7},
    urldate = {2025-05-15},
    journal = {Sensors},
    author = {Wang, Lulu},
    month = jul,
    year = {2017},
    note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
    keywords = {biomarker, breast cancer, microwave biosensor, microwave imaging, microwave-sensing, radio frequency biosensor},
    pages = {1572},
}
@incollection{orrantia-borunda_subtypes_2022,
    address = {Brisbane (AU)},
    title = {Subtypes of {Breast} {Cancer}},
    copyright = {Copyright: The Authors.; The authors confirm that the materials included in this chapter do not violate copyright laws. Where relevant, appropriate permissions have been obtained from the original copyright holder(s), and all original sources have been appropriately acknowledged or referenced.},
    isbn = {978-0-6453320-3-2},
    url = {http://www.ncbi.nlm.nih.gov/books/NBK583808/},
    abstract = {Breast cancer is a genetically and clinically heterogeneous disease with multiple subtypes. The classification of these subtypes has evolved over the years. The most common and widely accepted classification of breast cancer is from an immunohistochemical perspective, based on the expression of the following hormone receptors: estrogen (ER), progesterone (PR) and human epidermal growth factor (HER2). Accordingly, the following four subtypes of breast cancer are widely recognized: luminal A, luminal B, HER2-positive, and triple-negative. With the recent advances in cancer research, and an increased molecular understanding of breast cancer, the current clinical model for classification of breast cancer may be benefit from the addition of several molecular markers such as miRNAs (let-7, miR-155, miR-150, miR-153) and mutations (p53, BRCA 1 and 2 genes). This chapter provides an overview of the characteristics of these four subtypes of breast cancer.},
    language = {eng},
    urldate = {2025-05-15},
    booktitle = {Breast {Cancer}},
    publisher = {Exon Publications},
    author = {Orrantia-Borunda, Erasmo and Anchondo-Nuñez, Patricia and Acuña-Aguilar, Lucero Evelia and Gómez-Valles, Francisco Octavio and Ramírez-Valdespino, Claudia Adriana},
    editor = {Mayrovitz, Harvey N.},
    year = {2022},
    pmid = {36122153},
}
@article{pattanaik_breast_2022,
    title = {Breast {Cancer} {Classification} from {Mammogram} {Images} {Using} {Extreme} {Learning} {Machine}-{Based} {DenseNet121} {Model}},
    volume = {2022},
    copyright = {Copyright © 2022 Raj Kumar Pattanaik et al.},
    issn = {1687-7268},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/2731364},
    doi = {10.1155/2022/2731364},
    abstract = {Breast cancer is characterized by abnormal discontinuities in the lining cells of a woman’s milk duct. Large numbers of women die from breast cancer as a result of developing symptoms in the milk ducts. If the diagnosis is made early, the death rates can be decreased. For radiologists and physicians, manually analyzing mammography images for breast cancer become time-consuming. To prevent manual analysis and simplify the work of classification, this paper introduces a novel hybrid DenseNet121-based Extreme Learning Machine Model (ELM) for classifying breast cancer from mammogram images. The mammogram images were processed through preprocessing and data augmentation phase. The features were collected separately after the pooling and flatten layer at the first stage of the classification. Further, the features are fed as input to the proposed DenseNet121-ELM model’s fully connected layer as input. An extreme learning machine model has replaced the fully connected layer. The weights of the extreme learning machine have been updated by the AdaGrad optimization algorithm to increase the model’s robustness and performance. Due to its faster convergence speed than other optimization techniques, the AdaGrad algorithm optimization was chosen. In this research, the Digital Database for Screening Mammography (DDSM) dataset mammogram images were utilized, and the results are presented. We have considered the batch size of 32, 64, and 128 for the performance measure, accuracy, sensitivity, specificity, and computational time. The proposed DenseNet121+ELM model achieves 99.47\% and 99.14\% as training accuracy and testing accuracy for batch size 128. Also, it achieves specificity, sensitivity, and computational time of 99.37\%, 99.94\%, and 159.7731 minutes, respectively. Further, the comparison result of performance measures is presented for batch sizes 32, 64, and 128 to show the robustness of the proposed DenseNet121+ELM model. The automatic classification performance of the DenseNet121+ELM model has much potential to be applied to the clinical diagnosis of breast cancer.},
    language = {en},
    number = {1},
    urldate = {2025-05-15},
    journal = {Journal of Sensors},
    author = {Pattanaik, Raj Kumar and Mishra, Satyasis and Siddique, Mohammed and Gopikrishna, Tiruveedula and Satapathy, Sunita},
    year = {2022},
    note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1155/2022/2731364},
    pages = {2731364},
}
@article{meenalochini_deep_2024,
    title = {A {Deep} {Learning} {Based} {Breast} {Cancer} {Classification} {System} {Using} {Mammograms}},
    volume = {19},
    issn = {2093-7423},
    url = {https://doi.org/10.1007/s42835-023-01747-x},
    doi = {10.1007/s42835-023-01747-x},
    abstract = {An automatic breast cancer detection and classification system plays an essential role in medical imaging applications. But accurate disease identification is one of the complicated processes due to the existence of noisy contents and irrelevant structure of the original images. In conventional works, various medical image processing techniques have been developed for accurately classifying the types of breast cancer. Still, it confronts difficulties due to the aspects of increased complexity in computations, error values, false positives, and misclassification outputs. Hence, this research work proposes to develop an optimization-based classification system for the breast cancer identification system. Here, the Gaussian filtering and Adaptive Histogram Equalization (AHE) techniques are utilized for preprocessing the original mammogram images by eliminating the noisy contents and enhancing the contrast of an image. Then, the Markov Random Adaptive Segmentation (MRAS) technique is employed for detecting the boundary region based on the random value selection. To make the classifying procedure easier, the set of features is optimally extracted from the segmented region with the help of a Genetic Algorithm (GA). In which, the global best fitness value is estimated by using the crossover, mutation, and selection operations. Finally, the Convolutional Neural Network (CNN) classification technique is utilized for categorizing the image as to whether normal or abnormal with its type. The entire performance analysis of the suggested model is validated and compared using multiple measures during the evaluation. In the proposed method GA performs feature selection and prunes unnecessary features. The major goal is to improve the classification performance while reducing the number of features used. The proposed system GA-CNN provides improved performance results with a reduced error rate.The suggested GA-CNN increases accuracy (98.5), sensitivity (99.38), and specificity values (98.4) as compared to the existing technique by effectively identifying the classed label.},
    language = {en},
    number = {4},
    urldate = {2025-05-15},
    journal = {Journal of Electrical Engineering \& Technology},
    author = {Meenalochini, G. and Ramkumar, S.},
    month = may,
    year = {2024},
    keywords = {Automated Pattern Recognition, Breast cancer detection, Categorization, Computer Imaging, Vision, Pattern Recognition and Graphics, Contrast enhancement, Convolutional neural network (CNN) based classification, Genetic algorithm, Genetic algorithm (GA) based optimization, Image Processing, Learning algorithms, Machine Learning, Markov random adaptive segmentation (MRAS), Preprocessing},
    pages = {2637--2650},
}
@article{zahoor_breast_2022,
    title = {Breast {Cancer} {Mammograms} {Classification} {Using} {Deep} {Neural} {Network} and {Entropy}-{Controlled} {Whale} {Optimization} {Algorithm}},
    volume = {12},
    issn = {2075-4418},
    url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8871265/},
    doi = {10.3390/diagnostics12020557},
    abstract = {Breast cancer has affected many women worldwide. To perform detection and classification of breast cancer many computer-aided diagnosis (CAD) systems have been established because the inspection of the mammogram images by the radiologist is a difficult and time taken task. To early diagnose the disease and provide better treatment lot of CAD systems were established. There is still a need to improve existing CAD systems by incorporating new methods and technologies in order to provide more precise results. This paper aims to investigate ways to prevent the disease as well as to provide new methods of classification in order to reduce the risk of breast cancer in women’s lives. The best feature optimization is performed to classify the results accurately. The CAD system’s accuracy improved by reducing the false-positive rates.The Modified Entropy Whale Optimization Algorithm (MEWOA) is proposed based on fusion for deep feature extraction and perform the classification. In the proposed method, the fine-tuned MobilenetV2 and Nasnet Mobile are applied for simulation. The features are extracted, and optimization is performed. The optimized features are fused and optimized by using MEWOA. Finally, by using the optimized deep features, the machine learning classifiers are applied to classify the breast cancer images. To extract the features and perform the classification, three publicly available datasets are used: INbreast, MIAS, and CBIS-DDSM. The maximum accuracy achieved in INbreast dataset is 99.7\%, MIAS dataset has 99.8\% and CBIS-DDSM has 93.8\%. Finally, a comparison with other existing methods is performed, demonstrating that the proposed algorithm outperforms the other approaches.},
    number = {2},
    urldate = {2025-05-15},
    journal = {Diagnostics},
    author = {Zahoor, Saliha and Shoaib, Umar and Lali, Ikram Ullah},
    month = feb,
    year = {2022},
    pmid = {35204646},
    pmcid = {PMC8871265},
    pages = {557},
}
@article{mota_breast_2024,
    title = {Breast {Cancer} {Molecular} {Subtype} {Prediction}: {A} {Mammography}-{Based} {AI} {Approach}},
    volume = {12},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    issn = {2227-9059},
    shorttitle = {Breast {Cancer} {Molecular} {Subtype} {Prediction}},
    url = {https://www.mdpi.com/2227-9059/12/6/1371},
    doi = {10.3390/biomedicines12061371},
    abstract = {Breast cancer remains a leading cause of mortality among women, with molecular subtypes significantly influencing prognosis and treatment strategies. Currently, identifying the molecular subtype of cancer requires a biopsy—a specialized, expensive, and time-consuming procedure, often yielding to results that must be supported with additional biopsies due to technique errors or tumor heterogeneity. This study introduces a novel approach for predicting breast cancer molecular subtypes using mammography images and advanced artificial intelligence (AI) methodologies. Using the OPTIMAM imaging database, 1397 images from 660 patients were selected. The pretrained deep learning model ResNet-101 was employed to classify tumors into five subtypes: Luminal A, Luminal B1, Luminal B2, HER2, and Triple Negative. Various classification strategies were studied: binary classifications (one vs. all others, specific combinations) and multi-class classification (evaluating all subtypes simultaneously). To address imbalanced data, strategies like oversampling, undersampling, and data augmentation were explored. Performance was evaluated using accuracy and area under the receiver operating characteristic curve (AUC). Binary classification results showed a maximum average accuracy and AUC of 79.02\% and 64.69\%, respectively, while multi-class classification achieved an average AUC of 60.62\% with oversampling and data augmentation. The most notable binary classification was HER2 vs. non-HER2, with an accuracy of 89.79\% and an AUC of 73.31\%. Binary classification for specific combinations of subtypes revealed an accuracy of 76.42\% for HER2 vs. Luminal A and an AUC of 73.04\% for HER2 vs. Luminal B1. These findings highlight the potential of mammography-based AI for non-invasive breast cancer subtype prediction, offering a promising alternative to biopsies and paving the way for personalized treatment plans.},
    language = {en},
    number = {6},
    urldate = {2025-05-15},
    journal = {Biomedicines},
    author = {Mota, Ana M. and Mendes, João and Matela, Nuno},
    month = jun,
    year = {2024},
    note = {Number: 6
Publisher: Multidisciplinary Digital Publishing Institute},
    keywords = {artificial intelligence, breast cancer, deep learning, mammography, molecular subtypes, personalized medicine},
    pages = {1371},
}
@article{ben_rabah_multimodal_2025,
    title = {A {Multimodal} {Deep} {Learning} {Model} for the {Classification} of {Breast} {Cancer} {Subtypes}},
    volume = {15},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    issn = {2075-4418},
    url = {https://www.mdpi.com/2075-4418/15/8/995},
    doi = {10.3390/diagnostics15080995},
    abstract = {Background: Breast cancer is a heterogeneous disease with distinct molecular subtypes, each requiring tailored therapeutic strategies. Accurate classification of these subtypes is crucial for optimizing treatment and improving patient outcomes. While immunohistochemistry remains the gold standard for subtyping, it is invasive and may not fully capture tumor heterogeneity. Artificial Intelligence (AI), particularly Deep Learning (DL), offers a promising non-invasive alternative by analyzing medical imaging data. Methods: In this study, we propose a multimodal DL model that integrates mammography images with clinical metadata to classify breast lesions into five categories: benign, luminal A, luminal B, HER2-enriched, and triple-negative. Using the publicly available Chinese Mammography Database (CMMD), our model was trained and evaluated on a dataset of 4056 images from 1775 patients. Results: The proposed multimodal approach significantly outperformed a unimodal model based solely on mammography images, achieving an AUC of 88.87\% for multiclass classification of these five categories, compared to 61.3\% AUC for the unimodal model. Conclusions: These findings highlight the potential of multimodal AI-driven approaches for non-invasive breast cancer subtype classification, paving the way for improved diagnostic precision and personalized treatment strategies.},
    language = {en},
    number = {8},
    urldate = {2025-04-18},
    journal = {Diagnostics},
    author = {Ben Rabah, Chaima and Sattar, Aamenah and Ibrahim, Ahmed and Serag, Ahmed},
    month = jan,
    year = {2025},
    note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
    keywords = {artificial intelligence, breast cancer, deep learning, molecular subtype classification, multimodal, personalized medicine},
    pages = {995},
}
@article{cai_online_2023,
    title = {An {Online} {Mammography} {Database} with {Biopsy} {Confirmed} {Types}},
    volume = {10},
    copyright = {2023 The Author(s)},
    issn = {2052-4463},
    url = {https://www.nature.com/articles/s41597-023-02025-1},
    doi = {10.1038/s41597-023-02025-1},
    abstract = {Breast carcinoma is the second largest cancer in the world among women. Early detection of breast cancer has been shown to increase the survival rate, thereby significantly increasing patients’ lifespan. Mammography, a noninvasive imaging tool with low cost, is widely used to diagnose breast disease at an early stage due to its high sensitivity. Although some public mammography datasets are useful, there is still a lack of open access datasets that expand beyond the white population as well as missing biopsy confirmation or with unknown molecular subtypes. To fill this gap, we build a database containing two online breast mammographies. The dataset named by Chinese Mammography Database (CMMD) contains 3712 mammographies involved 1775 patients, which is divided into two branches. The first dataset CMMD1 contains 1026 cases (2214 mammographies) with biopsy confirmed type of benign or malignant tumors. The second dataset CMMD2 includes 1498 mammographies for 749 patients with known molecular subtypes. Our database is constructed to enrich the diversity of mammography data and promote the development of relevant fields.},
    language = {en},
    number = {1},
    urldate = {2025-05-18},
    journal = {Scientific Data},
    author = {Cai, Hongmin and Wang, Jinhua and Dan, Tingting and Li, Jiao and Fan, Zhihao and Yi, Weiting and Cui, Chunyan and Jiang, Xinhua and Li, Li},
    month = mar,
    year = {2023},
    note = {Publisher: Nature Publishing Group},
    keywords = {Breast cancer, Prognostic markers},
    pages = {123},
}
@incollection{hussain_performance_2025,
    title = {Performance {Evaluation} of {Deep} {Learning} and {Transformer} {Models} {Using} {Multimodal} {Data} for {Breast} {Cancer} {Classification}},
    volume = {15199},
    url = {http://arxiv.org/abs/2410.10146},
    abstract = {Rising breast cancer (BC) occurrence and mortality are major global concerns for women. Deep learning (DL) has demonstrated superior diagnostic performance in BC classification compared to human expert readers. However, the predominant use of unimodal (digital mammography) features may limit the current performance of diagnostic models. To address this, we collected a novel multimodal dataset comprising both imaging and textual data. This study proposes a multimodal DL architecture for BC classification, utilising images (mammograms; four views) and textual data (radiological reports) from our new in-house dataset. Various augmentation techniques were applied to enhance the training data size for both imaging and textual data. We explored the performance of eleven SOTA DL architectures (VGG16, VGG19, ResNet34, ResNet50, MobileNet-v3, EffNet-b0, EffNet-b1, EffNet-b2, EffNet-b3, EffNet-b7, and Vision Transformer (ViT)) as imaging feature extractors. For textual feature extraction, we utilised either artificial neural networks (ANNs) or long short-term memory (LSTM) networks. The combined imaging and textual features were then inputted into an ANN classifier for BC classification, using the late fusion technique. We evaluated different feature extractor and classifier arrangements. The VGG19 and ANN combinations achieved the highest accuracy of 0.951. For precision, the VGG19 and ANN combination again surpassed other CNN and LSTM, ANN based architectures by achieving a score of 0.95. The best sensitivity score of 0.903 was achieved by the VGG16+LSTM. The highest F1 score of 0.931 was achieved by VGG19+LSTM. Only the VGG16+LSTM achieved the best area under the curve (AUC) of 0.937, with VGG16+LSTM closely following with a 0.929 AUC score.},
    urldate = {2025-05-19},
    author = {Hussain, Sadam and Ali, Mansoor and Naseem, Usman and Palomo, Beatriz Alejandra Bosques and Molina, Mario Alexis Monsivais and Abdala, Jorge Alberto Garza and Avalos, Daly Betzabeth Avendano and Cardona-Huerta, Servando and Gulliver, T. Aaron and Pena, Jose Gerardo Tamez},
    year = {2025},
    doi = {10.1007/978-3-031-73376-5_6},
    note = {arXiv:2410.10146 [eess]},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
    pages = {59--69},
}
@article{mckinney_international_2020,
    title = {International evaluation of an {AI} system for breast cancer screening},
    volume = {577},
    copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
    issn = {1476-4687},
    url = {https://www.nature.com/articles/s41586-019-1799-6},
    doi = {10.1038/s41586-019-1799-6},
    abstract = {Screening mammography aims to identify breast cancer at earlier stages of the disease, when treatment can be more successful1. Despite the existence of screening programmes worldwide, the interpretation of mammograms is affected by high rates of false positives and false negatives2. Here we present an artificial intelligence (AI) system that is capable of surpassing human experts in breast cancer prediction. To assess its performance in the clinical setting, we curated a large representative dataset from the UK and a large enriched dataset from the USA. We show an absolute reduction of 5.7\% and 1.2\% (USA and UK) in false positives and 9.4\% and 2.7\% in false negatives. We provide evidence of the ability of the system to generalize from the UK to the USA. In an independent study of six radiologists, the AI system outperformed all of the human readers: the area under the receiver operating characteristic curve (AUC-ROC) for the AI system was greater than the AUC-ROC for the average radiologist by an absolute margin of 11.5\%. We ran a simulation in which the AI system participated in the double-reading process that is used in the UK, and found that the AI system maintained non-inferior performance and reduced the workload of the second reader by 88\%. This robust assessment of the AI system paves the way for clinical trials to improve the accuracy and efficiency of breast cancer screening.},
    language = {en},
    number = {7788},
    urldate = {2025-05-19},
    journal = {Nature},
    author = {McKinney, Scott Mayer and Sieniek, Marcin and Godbole, Varun and Godwin, Jonathan and Antropova, Natasha and Ashrafian, Hutan and Back, Trevor and Chesus, Mary and Corrado, Greg S. and Darzi, Ara and Etemadi, Mozziyar and Garcia-Vicente, Florencia and Gilbert, Fiona J. and Halling-Brown, Mark and Hassabis, Demis and Jansen, Sunny and Karthikesalingam, Alan and Kelly, Christopher J. and King, Dominic and Ledsam, Joseph R. and Melnick, David and Mostofi, Hormuz and Peng, Lily and Reicher, Joshua Jay and Romera-Paredes, Bernardino and Sidebottom, Richard and Suleyman, Mustafa and Tse, Daniel and Young, Kenneth C. and De Fauw, Jeffrey and Shetty, Shravya},
    month = jan,
    year = {2020},
    note = {Publisher: Nature Publishing Group},
    keywords = {Breast cancer, Preclinical research},
    pages = {89--94},
}
@article{rashmi_predicting_2021,
    title = {Predicting the molecular subtype of breast cancer based on mammography and ultrasound findings},
    volume = {28},
    copyright = {Thieme Medical and Scientific Publishers Pvt. Ltd. A-12, 2nd Floor, Sector 2, Noida-201301 UP, India},
    issn = {0971-3026},
    url = {https://www.thieme-connect.de/products/ejournals/abstract/10.4103/ijri.IJRI_78_18},
    doi = {10.4103/ijri.IJRI_78_18},
    abstract = {Aim: To determine the correlation between mammography and ultrasound features of breast cancer with molecular subtypes and to calculate the predictive value of these features. Materials and Method: This is a prospective study of consecutive patients with breast cancer presenting between January 2016 and July 2017, who underwent mammography and/or ultrasound of breast and excision of the breast mass. Patients with contralateral breast mass, metastases, h/o prior cancer treatment, and other malignancies were excluded. On mammography, the presence or absence of microcalcification was noted. On ultrasound examination size, margins, microcalcification, posterior acoustic features, vascularity, and axillary nodes were assessed. Margins were categorized into circumscribed and non-circumscribed. Posterior acoustic features were classified into four categories: shadowing, enhancement, mixed, and no changes. Vascularity was assessed based on Adler's index into grades 0, 1, 2, and 3. Grades 0 and 1 were considered low and 2 and 3 were high. Results: Tumors with non-circumscribed margins and posterior acoustic shadowing were likely to be luminal A or B subtype of breast cancer [odds ratio (JR) 5.78; 95\% confidence interval (CI) 3.68–9.80; P {\textless} 0.0001]. Tumors with non-circumscribed margins, posterior acoustic shadowing, and high vascularity were more likely to be luminal B subtype (JR 2.88; 95\% CI 2–4.14; P- {\textless}0.0001). Tumors with microcalcification and posterior mixed acoustic pattern were strongly associated to be HER2-positive (JR 5.48; 95\% CI 3.06–9.80; P {\textless} 0.0001). Tumors with circumscribed margins and posterior acoustic enhancement were highly suggestive of triple-negative breast cancer (JR 7.06; 95\% CI 4.64–10.73; P {\textless} 0.0001). Conclusion: Microcalcification detected on mammography and certain ultrasound features such as circumscribed or non-circumscribed margins, posterior acoustic features, and vascularity are strongly correlated in predicting the molecular subtypes of breast cancer, and thus may further expand the role of conventional breast imaging.},
    language = {en},
    urldate = {2025-05-19},
    journal = {Indian Journal of Radiology and Imaging},
    author = {Rashmi, S. and Kamala, S. and Murthy, S. Sudha and Kotha, Swapna and Rao, Y. Suhas and Chaudhary, K. Veeraiah},
    month = jul,
    year = {2021},
    note = {Publisher: Thieme Medical and Scientific Publishers Pvt. Ltd.},
    pages = {354--361},
}
@article{goldhirsch_personalizing_2013,
    title = {Personalizing the treatment of women with early breast cancer: highlights of the {St} {Gallen} {International} {Expert} {Consensus} on the {Primary} {Therapy} of {Early} {Breast} {Cancer} 2013},
    volume = {24},
    issn = {0923-7534, 1569-8041},
    shorttitle = {Personalizing the treatment of women with early breast cancer},
    url = {https://www.annalsofoncology.org/article/S0923-7534(19)36964-9/fulltext},
    doi = {10.1093/annonc/mdt303},
    language = {English},
    number = {9},
    urldate = {2025-05-24},
    journal = {Annals of Oncology},
    author = {Goldhirsch, A. and Winer, E. P. and Coates, A. S. and Gelber, R. D. and Piccart-Gebhart, M. and Thürlimann, B. and Senn, H.-J. and Albain, Kathy S. and André, Fabrice and Bergh, Jonas and Bonnefoi, Hervé and Bretel-Morales, Denisse and Burstein, Harold and Cardoso, Fatima and Castiglione-Gertsch, Monica and Coates, Alan S. and Colleoni, Marco and Costa, Alberto and Curigliano, Giuseppe and Davidson, Nancy E. and Leo, Angelo Di and Ejlertsen, Bent and Forbes, John F. and Gelber, Richard D. and Gnant, Michael and Goldhirsch, Aron and Goodwin, Pamela and Goss, Paul E. and Harris, Jay R. and Hayes, Daniel F. and Hudis, Clifford A. and Ingle, James N. and Jassem, Jacek and Jiang, Zefei and Karlsson, Per and Loibl, Sibylle and Morrow, Monica and Namer, Moise and Osborne, C. Kent and Partridge, Ann H. and Penault-Llorca, Frédérique and Perou, Charles M. and Piccart-Gebhart, Martine J. and Pritchard, Kathleen I. and Rutgers, Emiel J. T. and Sedlmayer, Felix and Semiglazov, Vladimir and Shao, Zhi-Ming and Smith, Ian and Thürlimann, Beat and Toi, Masakazu and Tutt, Andrew and Untch, Michael and Viale, Giuseppe and Watanabe, Toru and Wilcken, Nicholas and Winer, Eric P. and Wood, William C.},
    month = sep,
    year = {2013},
    pmid = {23917950},
    note = {Publisher: Elsevier},
    keywords = {St Gallen Consensus, early breast cancer, radiation therapy, subtypes, surgery, systemic adjuvant therapies},
    pages = {2206--2223},
}
@article{mauricio_comparing_2023,
    title = {Comparing {Vision} {Transformers} and {Convolutional} {Neural} {Networks} for {Image} {Classification}: {A} {Literature} {Review}},
    volume = {13},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    issn = {2076-3417},
    shorttitle = {Comparing {Vision} {Transformers} and {Convolutional} {Neural} {Networks} for {Image} {Classification}},
    url = {https://www.mdpi.com/2076-3417/13/9/5521},
    doi = {10.3390/app13095521},
    abstract = {Transformers are models that implement a mechanism of self-attention, individually weighting the importance of each part of the input data. Their use in image classification tasks is still somewhat limited since researchers have so far chosen Convolutional Neural Networks for image classification and transformers were more targeted to Natural Language Processing (NLP) tasks. Therefore, this paper presents a literature review that shows the differences between Vision Transformers (ViT) and Convolutional Neural Networks. The state of the art that used the two architectures for image classification was reviewed and an attempt was made to understand what factors may influence the performance of the two deep learning architectures based on the datasets used, image size, number of target classes (for the classification problems), hardware, and evaluated architectures and top results. The objective of this work is to identify which of the architectures is the best for image classification and under what conditions. This paper also describes the importance of the Multi-Head Attention mechanism for improving the performance of ViT in image classification.},
    language = {en},
    number = {9},
    urldate = {2025-05-25},
    journal = {Applied Sciences},
    author = {Maurício, José and Domingues, Inês and Bernardino, Jorge},
    month = jan,
    year = {2023},
    note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
    keywords = {Vision Transformers (ViT), convolutional neural networks, image classification, multi-head attention, transformers},
    pages = {5521},
}